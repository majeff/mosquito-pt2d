"""
å®Œæ•´èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµ
æ•´åˆ AI æª¢æ¸¬ã€é›²å°è¿½è¹¤ã€å½±åƒä¸²æµæ–¼ä¸€é«”

âš ï¸ é€™æ˜¯å”¯ä¸€éœ€è¦é‹è¡Œçš„ç¨‹å¼ï¼
- âœ… åŒ…å« AI æª¢æ¸¬ (MosquitoDetector)
- âœ… åŒ…å«é›²å°æ§åˆ¶ (PT2DController)
- âœ… åŒ…å«è¿½è¹¤é‚è¼¯ (MosquitoTracker)
- âœ… åŒ…å«å½±åƒä¸²æµ (StreamingServer)
- âœ… AI è² è¼‰ä¸æœƒé‡è¤‡ï¼ˆæ¯å¹€åªæª¢æ¸¬ä¸€æ¬¡ï¼‰
- âœ… æ”¯æ´é›™ç›®æ”åƒé ­

ä½¿ç”¨æ–¹å¼ï¼š
    python streaming_tracking_system.py
"""

# Copyright 2025 Arduino PT2D Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from streaming_server import StreamingServer
from mosquito_detector import MosquitoDetector
from mosquito_tracker import MosquitoTracker
from pt2d_controller import PT2DController
from depth_estimator import DepthEstimator
from config_loader import config
import sys
import cv2
import numpy as np
import time
import argparse
import signal
import logging
import traceback
from pathlib import Path
from collections import deque

# é…ç½® logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class StreamingTrackingSystem:
    """æ•´åˆçš„èšŠå­è¿½è¹¤èˆ‡ä¸²æµç³»çµ±"""

    def __init__(self,
                 arduino_port: str = '/dev/ttyUSB0',
                 camera_id: int = 0,
                 model_path: str = "models/mosquito",
                 http_port: int = 5000,
                 dual_camera: bool = True,
                 stream_mode: str = "single",
                 save_samples: bool = None,
                 sample_conf_range: tuple = None,
                 enable_depth: bool = True,
                 enable_rtsp: bool = False,
                 rtsp_url: str = None,
                 rtsp_bitrate: int = 2000):
        """åˆå§‹åŒ–å®Œæ•´ç³»çµ±"""
        logger.info("=" * 60)
        logger.info("ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµæ•´åˆå•Ÿå‹•")
        logger.info("=" * 60)

        # ç³»çµ±é…ç½®
        self.dual_camera = dual_camera
        self.stream_mode = stream_mode
        self.camera_id = camera_id
        self.enable_depth = enable_depth and dual_camera  # æ·±åº¦ä¼°è¨ˆéœ€è¦é›™ç›®æ”åƒé ­
        self._running = True  # é‹è¡Œæ¨™èªŒï¼Œç”¨æ–¼å„ªé›…é€€å‡º
        self.has_pt = False
        self.has_laser = False

        # æ”åƒé ­è§£æåº¦é…ç½®ï¼ˆå¾ config_loader è®€å–ï¼‰
        self.camera_width = config.camera_dual_width if dual_camera else 1920
        self.camera_height = config.camera_dual_height if dual_camera else 1080
        self.camera_fps = config.camera_dual_fps if dual_camera else 60

        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total_frames': 0,
            'unique_targets': 0,          # å”¯ä¸€ç›®æ¨™æ•¸ï¼ˆå»é‡å¾Œï¼‰
            'tracking_active': False,
            'samples_saved': 0,
            'start_time': time.time(),
            'last_illumination_info': {}
        }

        # å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰
        self.active_tracks = {}           # {track_id: {'last_seen': time, 'center': (x,y), 'lost_frames': int}}
        self.next_track_id = 1
        self.track_distance_threshold = 100  # åƒç´ è·é›¢é–¾å€¼ï¼ˆ<100èªç‚ºæ˜¯åŒä¸€ç›®æ¨™ï¼‰
        self.track_lost_frames_max = 30     # è¶…é30å¹€æœªè¦‹è¦–ç‚ºæ¶ˆå¤±

        # å–®ç›®éæ¿¾å™¨è¿½è¹¤æ•¸æ“šï¼ˆç”¨æ–¼æ™‚é–“é€£çºŒæ€§å’Œé‹å‹•åˆç†æ€§æª¢æŸ¥ï¼‰
        self.detection_history = {}       # {track_id: {'frames': int, 'positions': deque, 'static_frames': int}}
        self._deque_cls = deque

        # 1. åˆå§‹åŒ– AI æª¢æ¸¬å™¨ï¼ˆåªå‰µå»ºä¸€æ¬¡ï¼ï¼‰
        logger.info("[1/5] åˆå§‹åŒ– AI æª¢æ¸¬å™¨...")

        if save_samples is None:
            save_samples = config.save_uncertain_samples
        if sample_conf_range is None:
            sample_conf_range = config.uncertain_conf_range

        self.detector = MosquitoDetector(
            model_path=model_path,
            confidence_threshold=config.confidence_threshold,
            imgsz=config.imgsz,
            save_uncertain_samples=save_samples,
            uncertain_conf_range=sample_conf_range,
            save_dir=config.sample_collection_dir,
            max_samples=config.max_samples,
            save_interval=config.save_interval,
            save_annotations=True,
            save_full_frame=False
        )
        logger.info(f"      âœ“ ä½¿ç”¨ {self.detector.backend.upper()} å¾Œç«¯")
        if save_samples:
            logger.info(f"      âœ“ æ¨£æœ¬å„²å­˜å·²å•Ÿç”¨ (ä¿¡å¿ƒåº¦ {sample_conf_range[0]}-{sample_conf_range[1]})")

        # 2. åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨èˆ‡è¿½è¹¤å™¨
        logger.info("[2/5] åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨...")
        try:
            self.pt_controller = PT2DController(config.arduino_port)
            if self.pt_controller.is_connected:
                logger.info(f"      âœ“ Arduino å·²é€£æ¥ ({config.arduino_port})")
                self.has_pt = True
                self.has_laser = True  # é›²å°é€£æ¥æˆåŠŸæ™‚å•Ÿç”¨é›·å°„åŠŸèƒ½
                logger.info("[3/5] åˆå§‹åŒ–è¿½è¹¤å™¨...")
                self.tracker = MosquitoTracker(
                    arduino_port=config.arduino_port,
                    camera_left_id=config.left_camera_id,
                    camera_right_id=config.right_camera_id,
                    camera_width=self.camera_width,
                    camera_height=self.camera_height
                )
                logger.info("      âœ“ è¿½è¹¤å™¨å·²å°±ç·’")
            else:
                logger.warning("      âš  ç„¡æ³•é€£æ¥ Arduinoï¼Œåƒ…é‹è¡Œæª¢æ¸¬æ¨¡å¼")
                self.has_pt = False
                self.has_laser = False
                self.tracker = None
        except Exception as e:
            logger.warning(f"      âš  é›²å°åˆå§‹åŒ–å¤±æ•—: {e}")
            self.has_pt = False
            self.has_laser = False
            self.tracker = None
            self.pt_controller = None

        # 4. åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        logger.info("[4/6] åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨...")
        if self.enable_depth:
            self.depth_estimator = None  # å°‡åœ¨é¦–å¹€æ™‚æ ¹æ“šå¯¦éš›è§£æåº¦åˆå§‹åŒ–
            logger.info("      â³ æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨é¦–å¹€æ™‚åˆå§‹åŒ–ï¼ˆæ ¹æ“šå¯¦éš›è§£æåº¦ï¼‰")
        else:
            self.depth_estimator = None
            logger.info("      âš  æ·±åº¦ä¼°è¨ˆæœªå•Ÿç”¨ï¼ˆéœ€è¦é›™ç›®æ”åƒé ­ï¼‰")

        # 5. åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨
        logger.info("[5/6] åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨...")
        self.server = StreamingServer(
            http_port=http_port,
            fps=config.stream_fps,
            rtsp_url=config.rtsp_url if enable_rtsp else None
        )
        self.server.run(threaded=True)
        logger.info(f"      âœ“ ä¸²æµä¼ºæœå™¨å·²å•Ÿå‹• (ç«¯å£ {http_port})")

        # 6. åˆå§‹åŒ– RTSP æ¨æµï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        self.enable_rtsp = enable_rtsp
        self.rtsp_url = rtsp_url
        self.rtsp_bitrate = rtsp_bitrate
        if enable_rtsp and rtsp_url:
            logger.info("[6/6] åˆå§‹åŒ– RTSP æ¨æµ...")
            logger.info(f"      âœ“ RTSP å·²é…ç½®")
            logger.info(f"         URL: {rtsp_url}")
            logger.info(f"         ç¢¼ç‡: {rtsp_bitrate}kbps")
            logger.info("      â³ RTSP æ¨æµå°‡åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹•...")
            self.rtsp_enabled = False
            self.rtsp_initialized = False
        else:
            if enable_rtsp:
                logger.warning("âš ï¸  RTSP å·²å•Ÿç”¨ä½† URL æœªè¨­å®š")
            self.rtsp_enabled = False
            self.rtsp_initialized = True

        # é›™ä¸²æµæ¨¡å¼ï¼ˆåƒ…åœ¨ dual_stream æ¨¡å¼ï¼‰
        self.server_right = None
        if stream_mode == "dual_stream" and dual_camera:
            self.server_right = StreamingServer(http_port=http_port + 1, fps=30)
            self.server_right.run(threaded=True)
            logger.info(f"      âœ“ å³å´ä¸²æµå·²å•Ÿå‹• (ç«¯å£ {http_port + 1})")

        logger.info("=" * 60)
        logger.info("ğŸ‰ ç³»çµ±å·²å®Œå…¨å•Ÿå‹•ï¼")
        logger.info("=" * 60)
        device_ip = config.device_ip or "[ä½ çš„IP]"
        local_url = f"http://{device_ip}:{http_port}"
        logger.info(f"ğŸ“± æœ¬æ©Ÿè¨ªå•: {local_url}")
        if config.external_url:
            logger.info(f"ğŸŒ é ç«¯è¨ªå•: {config.external_url}")
        if self.server_right:
            logger.info(f"ğŸ“± å³å´è¦–è§’ï¼ˆæœ¬æ©Ÿï¼‰: http://{device_ip}:{http_port + 1}")

        logger.info("â„¹ï¸  ç³»çµ±é…ç½®:")
        logger.info(f"   - AI æª¢æ¸¬: âœ“ å•Ÿç”¨ ({self.detector.backend.upper()})")
        logger.info(f"   - é›²å°è¿½è¹¤: {'âœ“ å•Ÿç”¨' if self.has_pt else 'âœ— åœç”¨'}")
        logger.info(f"   - é›·å°„æ¨™è¨˜: {'âœ“ å•Ÿç”¨' if self.has_laser else 'âœ— åœç”¨'}")
        logger.info(f"   - æ·±åº¦ä¼°è¨ˆ: {'âœ“ å•Ÿç”¨' if self.enable_depth else 'âœ— åœç”¨'}")
        logger.info(f"   - æ¨£æœ¬å„²å­˜: {'âœ“ å•Ÿç”¨' if save_samples else 'âœ— åœç”¨'}")
        logger.info(f"   - é›™ç›®æ”åƒé ­: {'âœ“ å•Ÿç”¨' if dual_camera else 'âœ— åœç”¨'}")
        logger.info(f"   - ä¸²æµæ¨¡å¼: {stream_mode}")

        logger.info("âš¡ æ€§èƒ½èªªæ˜:")
        logger.info("   - AI è² è¼‰: æ¯å¹€åªåŸ·è¡Œä¸€æ¬¡æª¢æ¸¬")
        logger.info("   - è¨˜æ†¶é«”: å–®ä¸€æª¢æ¸¬å™¨å¯¦ä¾‹")
        logger.info("   - CPU: æœ€å„ªåŒ–åˆ©ç”¨")

        logger.info("ğŸ® æ§åˆ¶æ–¹å¼:")
        logger.info("   Ctrl+C - é€€å‡ºç³»çµ±")
        logger.info("   (é€šéç€è¦½å™¨è¨ªå• HTTP ä¸²æµæŸ¥çœ‹å½±åƒ)")

    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """è™•ç†å–®å¹€å½±åƒï¼ˆAI æª¢æ¸¬ + è¿½è¹¤ + æ¨™è¨»ï¼‰"""
        self.stats['total_frames'] += 1

        if self.enable_rtsp and not self.rtsp_initialized:
            h, w = frame.shape[:2]
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RTSP...")
            logger.info(f"   RTSP URL: {self.rtsp_url}")
            logger.info(f"   RTSP ç¢¼ç‡: {self.rtsp_bitrate}kbps")
            logger.info(f"   å¹€å°ºå¯¸: {w}x{h}")
            try:
                if self.server.enable_rtsp_push(w, h, bitrate=self.rtsp_bitrate):
                    logger.info("âœ… RTSP æ¨æµå·²å•Ÿå‹•")
                    self.rtsp_enabled = True
                else:
                    logger.warning("âš ï¸  RTSP æ¨æµå•Ÿå‹•è¿”å› False")
            except Exception as e:
                logger.error(f"âŒ RTSP åˆå§‹åŒ–å¤±æ•—: {e}")
                traceback.print_exc()
            finally:
                self.rtsp_initialized = True

        if self.dual_camera:
            height, width = frame.shape[:2]
            mid = width // 2
            left_frame = frame[:, :mid]
            right_frame = frame[:, mid:]

            if self.enable_depth and self.depth_estimator is None:
                single_width = left_frame.shape[1]
                logger.info(f"ğŸ”§ åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå–®çœ¼è§£æåº¦: {single_width}Ã—{left_frame.shape[0]}ï¼‰")
                self.depth_estimator = DepthEstimator(
                    focal_length=3.0,
                    baseline=120.0,
                    image_width=single_width,
                    sensor_width=5.0
                )
                logger.info("      âœ“ æ·±åº¦ä¼°è¨ˆå·²å•Ÿç”¨ï¼ˆæ¸¬è·ç¯„åœ: 0.5-5mï¼‰")
        else:
            left_frame = frame
            right_frame = None

        detections, result_left, illumination_info = self.detector.detect(left_frame, is_dual_left=self.dual_camera)

        if detections:
            detections = [d for d in detections if d.get('confidence', 0) < 1.0]
            if len([d for d in detections if d.get('confidence', 0) >= 1.0]) > 0:
                logger.debug(f"å·²éæ¿¾ {len([d for d in detections if d.get('confidence', 0) >= 1.0])} å€‹ä¿¡å¿ƒåº¦=1.0çš„ç•°å¸¸æª¢æ¸¬")

        if detections:
            self._update_unique_targets(detections)

            if self.depth_estimator and right_frame is not None:
                valid_detections = []
                for detection in detections:
                    bbox = detection.get('bbox')
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        depth_info = self.depth_estimator.estimate_depth_for_detection(
                            left_frame, right_frame, (x1, y1, x2, y2)
                        )
                        if depth_info:
                            detection['depth'] = depth_info['depth']
                            detection['distance_cm'] = depth_info['distance_cm']
                            detection['object_size_mm'] = depth_info.get('object_size_mm', 0)
                            from config_loader import config
                            obj_size = depth_info.get('object_size_mm', 0)
                            if config.min_mosquito_size_mm <= obj_size <= config.max_mosquito_size_mm:
                                valid_detections.append(detection)
                        else:
                            valid_detections.append(detection)
                    else:
                        valid_detections.append(detection)
                detections = valid_detections
            else:
                detections = self._apply_monocular_filters(detections)

        if self.tracker and detections:
            self.tracker.update(detections)
            self.stats['tracking_active'] = True
        else:
            self.stats['tracking_active'] = False

        self.stats['last_illumination_info'] = illumination_info

        if detections:
            self._log_detection_details(detections)

        result_left = self._draw_detections_with_depth(result_left, detections)
        self._draw_system_info(result_left, detections, illumination_info)

        if self.stream_mode == "side_by_side" and right_frame is not None:
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            combined = np.hstack([result_left, right_frame])
            mid = combined.shape[1] // 2
            cv2.line(combined, (mid, 0), (mid, combined.shape[0]), (0, 255, 255), 2)
            return combined

        if self.stream_mode == "dual_stream" and right_frame is not None:
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            return result_left, right_frame

        return result_left

    def _draw_detections_with_depth(self, frame: np.ndarray, detections: list) -> np.ndarray:
        frame = self.detector.draw_detections(frame, detections)
        if self.depth_estimator and detections:
            for detection in detections:
                bbox = detection.get('bbox')
                depth = detection.get('depth')
                distance_cm = detection.get('distance_cm')
                if bbox and distance_cm:
                    x1, y1, x2, y2 = bbox
                    obj_size = detection.get('object_size_mm', 0)
                    distance_text = f"{distance_cm:.1f}cm | {obj_size:.1f}mm" if obj_size > 0 else f"{distance_cm:.1f}cm"
                    text_size = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    text_x = x1
                    text_y = y2 + 25
                    cv2.rectangle(frame,
                                  (text_x, text_y - text_size[1] - 5),
                                  (text_x + text_size[0] + 5, text_y + 5),
                                  (0, 0, 0), -1)
                    cv2.putText(frame, distance_text,
                                (text_x + 2, text_y),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
        return frame

    def _update_unique_targets(self, detections: list):
        current_time = time.time()
        for track_id in self.active_tracks:
            self.active_tracks[track_id]['lost_frames'] += 1

        for detection in detections:
            center = detection.get('center', (0, 0))
            matched_track_id = None
            min_distance = self.track_distance_threshold
            for track_id, track_info in self.active_tracks.items():
                if track_info['lost_frames'] > self.track_lost_frames_max:
                    continue
                track_center = track_info['center']
                distance = np.sqrt((center[0] - track_center[0])**2 + (center[1] - track_center[1])**2)
                if distance < min_distance:
                    min_distance = distance
                    matched_track_id = track_id
            if matched_track_id is not None:
                self.active_tracks[matched_track_id]['center'] = center
                self.active_tracks[matched_track_id]['last_seen'] = current_time
                self.active_tracks[matched_track_id]['lost_frames'] = 0
                detection['track_id'] = matched_track_id
            else:
                new_track_id = self.next_track_id
                self.next_track_id += 1
                self.active_tracks[new_track_id] = {
                    'center': center,
                    'last_seen': current_time,
                    'lost_frames': 0
                }
                self.stats['unique_targets'] += 1
                detection['track_id'] = new_track_id

        tracks_to_remove = [
            track_id for track_id, track_info in self.active_tracks.items()
            if track_info['lost_frames'] > self.track_lost_frames_max
        ]
        for track_id in tracks_to_remove:
            del self.active_tracks[track_id]
            if track_id in self.detection_history:
                del self.detection_history[track_id]

    def _apply_monocular_filters(self, detections: list) -> list:
        try:
            from config_loader import config
            ENABLE_BBOX_SIZE_FILTER = config.enable_bbox_size_filter
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            ENABLE_ASPECT_RATIO_FILTER = config.enable_aspect_ratio_filter
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
            ENABLE_TEMPORAL_FILTER = config.enable_temporal_filter
            MIN_CONSECUTIVE_FRAMES = config.min_consecutive_frames
            ENABLE_MOTION_FILTER = config.enable_motion_filter
            MAX_MOVEMENT_PX_PER_FRAME = config.max_movement_px_per_frame
            MAX_STATIC_FRAMES = config.max_static_frames
            STATIC_THRESHOLD_PX = config.static_threshold_px
        except ImportError:
            ENABLE_BBOX_SIZE_FILTER = True
            MIN_BBOX_SIZE_PX = 10
            MAX_BBOX_SIZE_PX = 200
            ENABLE_ASPECT_RATIO_FILTER = True
            MIN_ASPECT_RATIO = 0.3
            MAX_ASPECT_RATIO = 3.0
            ENABLE_TEMPORAL_FILTER = True
            MIN_CONSECUTIVE_FRAMES = 3
            ENABLE_MOTION_FILTER = True
            MAX_MOVEMENT_PX_PER_FRAME = 150
            MAX_STATIC_FRAMES = 60
            STATIC_THRESHOLD_PX = 5

        valid_detections = []
        for detection in detections:
            bbox = detection.get('bbox')
            if not bbox:
                continue

            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            center = detection.get('center', ((x1 + x2) // 2, (y1 + y2) // 2))
            track_id = detection.get('track_id')

            if ENABLE_BBOX_SIZE_FILTER:
                size = max(width, height)
                if size < MIN_BBOX_SIZE_PX or size > MAX_BBOX_SIZE_PX:
                    logger.debug(f"æ¡†å¤§å°éæ¿¾: {size}px ä¸åœ¨ {MIN_BBOX_SIZE_PX}-{MAX_BBOX_SIZE_PX}px ç¯„åœ")
                    continue

            if ENABLE_ASPECT_RATIO_FILTER:
                aspect_ratio = width / max(height, 1)
                if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
                    logger.debug(f"å¯¬é«˜æ¯”éæ¿¾: {aspect_ratio:.2f} ä¸åœ¨ {MIN_ASPECT_RATIO}-{MAX_ASPECT_RATIO} ç¯„åœ")
                    continue

            if ENABLE_TEMPORAL_FILTER and track_id is not None:
                if track_id not in self.detection_history:
                    self.detection_history[track_id] = {
                        'frames': 1,
                        'positions': self._deque_cls(maxlen=10),
                        'static_frames': 0
                    }
                    self.detection_history[track_id]['positions'].append(center)
                else:
                    self.detection_history[track_id]['frames'] += 1
                    self.detection_history[track_id]['positions'].append(center)

                if self.detection_history[track_id]['frames'] < MIN_CONSECUTIVE_FRAMES:
                    logger.debug(f"æ™‚é–“é€£çºŒæ€§éæ¿¾: track_{track_id} åƒ…å‡ºç¾ {self.detection_history[track_id]['frames']} å¹€")
                    continue

            if ENABLE_MOTION_FILTER and track_id is not None and track_id in self.detection_history:
                history = self.detection_history[track_id]
                positions = history['positions']

                if len(positions) >= 2:
                    prev_pos = positions[-2]
                    curr_pos = center
                    movement = np.sqrt((curr_pos[0] - prev_pos[0])**2 + (curr_pos[1] - prev_pos[1])**2)

                    if movement > MAX_MOVEMENT_PX_PER_FRAME:
                        logger.debug(f"é‹å‹•éå¿«éæ¿¾: track_{track_id} ç§»å‹• {movement:.1f}px > {MAX_MOVEMENT_PX_PER_FRAME}px")
                        continue

                    if movement < STATIC_THRESHOLD_PX:
                        history['static_frames'] += 1
                        if history['static_frames'] > MAX_STATIC_FRAMES:
                            logger.debug(f"éœæ­¢éä¹…éæ¿¾: track_{track_id} éœæ­¢ {history['static_frames']} å¹€")
                            continue
                    else:
                        history['static_frames'] = 0

            valid_detections.append(detection)

        return valid_detections

    def _log_detection_details(self, detections: list):
        try:
            from config_loader import config
            MIN_MOSQUITO_SIZE_MM = config.min_mosquito_size_mm
            MAX_MOSQUITO_SIZE_MM = config.max_mosquito_size_mm
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
        except ImportError:
            MIN_MOSQUITO_SIZE_MM = 3
            MAX_MOSQUITO_SIZE_MM = 15
        # è©³ç´°æ—¥èªŒç•™ç©ºï¼ˆç¶­æŒåŸè¡Œç‚ºï¼‰

    def run(self):
        cap = cv2.VideoCapture(self.camera_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
        cap.set(cv2.CAP_PROP_FPS, self.camera_fps)

        if not cap.isOpened():
            logger.error(f"âŒ ç„¡æ³•æ‰“é–‹æ”åƒé ­ {self.camera_id}")
            return

        logger.info(f"ğŸ¥ æ”åƒé ­å·²æ‰“é–‹: {self.camera_width}x{self.camera_height}@{self.camera_fps}fps")

        try:
            frame_count = 0
            start_time = time.time()

            while self._running:
                ret, frame = cap.read()
                if not ret:
                    logger.error("âŒ ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                    break

                processed_frame = self.process_frame(frame)

                if self.stream_mode == "dual_stream" and isinstance(processed_frame, tuple):
                    left_frame, right_frame = processed_frame
                    self.server.push_frame(left_frame)
                    if self.server_right:
                        self.server_right.push_frame(right_frame)
                else:
                    self.server.push_frame(processed_frame)

                frame_count += 1

                if frame_count % 100 == 0:
                    elapsed_time = time.time() - start_time
                    fps = 100 / elapsed_time if elapsed_time > 0 else 0
                    logger.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š: {fps:.1f} FPS, "
                               f"ç¸½å¹€æ•¸: {frame_count}, "
                               f"å”¯ä¸€ç›®æ¨™: {self.stats['unique_targets']}, "
                               f"è¿½è¹¤ç‹€æ…‹: {'ğŸŸ¢' if self.stats['tracking_active'] else 'ğŸ”´'}")
                    start_time = time.time()

        except Exception as e:
            logger.error(f"âŒ ç³»çµ±é‹è¡Œç•°å¸¸: {e}")
            traceback.print_exc()
        finally:
            cap.release()
            logger.info("ğŸ“¹ æ”åƒé ­å·²é‡‹æ”¾")

    def stop(self):
        logger.info("ğŸ›‘ åœæ­¢ç³»çµ±...")
        self._running = False
        try:
            if getattr(self, 'server', None):
                self.server.stop()
            if getattr(self, 'server_right', None):
                self.server_right.stop()
            if getattr(self, 'pt_controller', None):
                self.pt_controller.disconnect()
            if getattr(self, 'detector', None):
                self.detector.cleanup()
        except Exception as e:
            logger.error(f"åœæ­¢ç³»çµ±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def signal_handler(sig, frame):
    global system
    logger.info('\nğŸ‘‹ æ”¶åˆ°é€€å‡ºä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰ç³»çµ±...')
    if system:
        system.stop()


def main():
    global system
    parser = argparse.ArgumentParser(description='ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµæ•´åˆ')
    parser.add_argument('--port', '-p', type=str, default=config.arduino_port,
                       help='Arduino ä¸²å£ (é è¨­: config.arduino_port)')
    parser.add_argument('--camera', '-c', type=int, default=config.left_camera_id,
                       help='æ”åƒé ­ ID (é è¨­: config.left_camera_id)')
    parser.add_argument('--model', type=str, default="models/mosquito",
                       help='AI æ¨¡å‹è·¯å¾‘ (é è¨­: models/mosquito)')
    parser.add_argument('--single', action='store_true',
                       help='å¼·åˆ¶å–®ç›®æ”åƒé ­æ¨¡å¼')
    parser.add_argument('--dual', action='store_true',
                       help='å¼·åˆ¶é›™ç›®æ”åƒé ­æ¨¡å¼')
    parser.add_argument('--mode', '-m', type=str, default="single",
                       choices=["single", "side_by_side", "dual_stream"],
                       help='ä¸²æµæ¨¡å¼ (é è¨­: single)')
    parser.add_argument('--port-http', type=int, default=config.stream_port,
                       help='HTTP ä¸²æµç«¯å£ (é è¨­: config.stream_port)')
    parser.add_argument('--save-samples', action='store_true',
                       help='å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬')
    parser.add_argument('--no-save-samples', dest='save_samples', action='store_false',
                       help='ä¸å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬')
    parser.set_defaults(save_samples=config.save_uncertain_samples)
    parser.add_argument('--rtsp', action='store_true',
                       help='å•Ÿç”¨ RTSP æ¨æµ')
    parser.add_argument('--rtsp-url', type=str, default=config.rtsp_url,
                       help='RTSP æ¨æµåœ°å€')
    parser.add_argument('--rtsp-bitrate', type=int, default=2000,
                       help='RTSP ç¢¼ç‡ (kbps, é è¨­: 2000)')

    args = parser.parse_args()

    dual_camera = args.dual or (not args.single and config.camera_dual_width > 1920)
    if args.single:
        logger.info("ğŸ“· å¼·åˆ¶ä½¿ç”¨å–®ç›®æ”åƒé ­æ¨¡å¼")
    elif args.dual:
        logger.info("ğŸ“· å¼·åˆ¶ä½¿ç”¨é›™ç›®æ”åƒé ­æ¨¡å¼")
    else:
        logger.info(f"ğŸ“· è‡ªå‹•æª¢æ¸¬æ”åƒé ­æ¨¡å¼: {'é›™ç›®' if dual_camera else 'å–®ç›®'}")

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    system = StreamingTrackingSystem(
        arduino_port=args.port,
        camera_id=args.camera,
        model_path=args.model,
        http_port=args.port_http,
        dual_camera=dual_camera,
        stream_mode=args.mode,
        save_samples=args.save_samples,
        enable_depth=dual_camera,
        enable_rtsp=args.rtsp,
        rtsp_url=args.rtsp_url,
        rtsp_bitrate=args.rtsp_bitrate
    )

    logger.info("ğŸš€ ç³»çµ±é–‹å§‹é‹è¡Œ... æŒ‰ Ctrl+C é€€å‡º")
    try:
        system.run()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ä½¿ç”¨è€…ä¸­æ–·ï¼Œæ­£åœ¨é—œé–‰ç³»çµ±...")
    except Exception as e:
        logger.error(f"ç³»çµ±é‹è¡ŒéŒ¯èª¤: {e}")
        traceback.print_exc()
    finally:
        system.stop()
        logger.info("âœ… ç³»çµ±å·²é—œé–‰")


if __name__ == "__main__":
    system = None
    main()

        self.track_lost_frames_max = 30     # è¶…é30å¹€æœªè¦‹è¦–ç‚ºæ¶ˆå¤±

        # å–®ç›®éæ¿¾å™¨è¿½è¹¤æ•¸æ“šï¼ˆç”¨æ–¼æ™‚é–“é€£çºŒæ€§å’Œé‹å‹•åˆç†æ€§æª¢æŸ¥ï¼‰
        self.detection_history = {}       # {track_id: {'frames': int, 'positions': deque, 'static_frames': int}}
        from collections import deque
        self._deque_cls = deque  # ä¾›å¾ŒçºŒæ–¹æ³•ä½¿ç”¨ï¼Œé¿å…æœªå®šç¾©

        # 1. åˆå§‹åŒ– AI æª¢æ¸¬å™¨ï¼ˆåªå‰µå»ºä¸€æ¬¡ï¼ï¼‰
        logger.info("[1/5] åˆå§‹åŒ– AI æª¢æ¸¬å™¨...")

        # å¦‚æœæœªæŒ‡å®šåƒæ•¸ï¼Œå‰‡ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        if save_samples is None:
            save_samples = config.save_uncertain_samples
        if sample_conf_range is None:
            sample_conf_range = config.uncertain_conf_range

        self.detector = MosquitoDetector(
            model_path=model_path,
            confidence_threshold=config.confidence_threshold,  # ä½¿ç”¨æ–°é…ç½®
            imgsz=config.imgsz,  # ä½¿ç”¨æ–°é…ç½®
            save_uncertain_samples=save_samples,
            uncertain_conf_range=sample_conf_range,  # ä½¿ç”¨å‚³å…¥çš„åƒæ•¸
            save_dir=config.sample_collection_dir,  # èˆ‡æ”¶é›†/æ¨™è¨»è·¯å¾‘ä¸€è‡´
            max_samples=config.max_samples,  # ä½¿ç”¨æ–°é…ç½®
            save_interval=config.save_interval,  # ä½¿ç”¨æ–°é…ç½®
            save_annotations=True,
            save_full_frame=False
        )
        logger.info(f"      âœ“ ä½¿ç”¨ {self.detector.backend.upper()} å¾Œç«¯")
        if save_samples:
            logger.info(f"      âœ“ æ¨£æœ¬å„²å­˜å·²å•Ÿç”¨ (ä¿¡å¿ƒåº¦ {sample_conf_range[0]}-{sample_conf_range[1]})")

        # 2. åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨èˆ‡è¿½è¹¤å™¨ï¼ˆå–®ä¸€è·¯å¾‘ï¼Œé¿å…æœªå®šç¾©ç‹€æ…‹ï¼‰
        logger.info("[2/5] åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨...")
        try:
            self.pt_controller = PT2DController(config.arduino_port)
            if self.pt_controller.is_connected:
                logger.info(f"      âœ“ Arduino å·²é€£æ¥ ({config.arduino_port})")
                self.has_pt = True
                self.has_laser = True  # é›²å°é€£æ¥æˆåŠŸæ™‚å•Ÿç”¨é›·å°„åŠŸèƒ½
                # 3. åˆå§‹åŒ–è¿½è¹¤å™¨ï¼ˆä¾è³´é›²å°é€£ç·šï¼‰
                logger.info("[3/5] åˆå§‹åŒ–è¿½è¹¤å™¨...")
                self.tracker = MosquitoTracker(
                    arduino_port=config.arduino_port,
                    camera_left_id=config.left_camera_id,
                    camera_right_id=config.right_camera_id,
                    camera_width=self.camera_width,
                    camera_height=self.camera_height
                )
                logger.info(f"      âœ“ è¿½è¹¤å™¨å·²å°±ç·’")
            else:
                logger.warning(f"      âš  ç„¡æ³•é€£æ¥ Arduinoï¼Œåƒ…é‹è¡Œæª¢æ¸¬æ¨¡å¼")
                self.has_pt = False
                self.has_laser = False
                self.tracker = None
        except Exception as e:
            logger.warning(f"      âš  é›²å°åˆå§‹åŒ–å¤±æ•—: {e}")
            self.has_pt = False
            self.has_laser = False
            self.tracker = None
            self.pt_controller = None

        # 4. åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        logger.info("[4/6] åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨...")
        if self.enable_depth:
            # æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨ run() ä¸­æ ¹æ“šå¯¦éš›è§£æåº¦åˆå§‹åŒ–
            self.depth_estimator = None
            logger.info(f"      â³ æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨é¦–å¹€æ™‚åˆå§‹åŒ–ï¼ˆæ ¹æ“šå¯¦éš›è§£æåº¦ï¼‰")
        else:
            self.depth_estimator = None
            logger.info(f"      âš  æ·±åº¦ä¼°è¨ˆæœªå•Ÿç”¨ï¼ˆéœ€è¦é›™ç›®æ”åƒé ­ï¼‰")

        # 5. åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨
        logger.info("[5/6] åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨...")
        self.server = StreamingServer(
            http_port=config.stream_port,  # ä½¿ç”¨æ–°é…ç½®
            fps=config.stream_fps,  # ä½¿ç”¨æ–°é…ç½®
            rtsp_url=config.rtsp_url if enable_rtsp else None  # ä½¿ç”¨æ–°é…ç½®
        )
        self.server.run(threaded=True)
        logger.info(f"      âœ“ ä¸²æµä¼ºæœå™¨å·²å•Ÿå‹• (ç«¯å£ {http_port})")

        # 6. åˆå§‹åŒ– RTSP æ¨æµï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        self.enable_rtsp = enable_rtsp
        self.rtsp_url = rtsp_url
        self.rtsp_bitrate = rtsp_bitrate
        if enable_rtsp and rtsp_url:
            logger.info("[6/6] åˆå§‹åŒ– RTSP æ¨æµ...")
            logger.info(f"      âœ“ RTSP å·²é…ç½®")
            logger.info(f"         URL: {rtsp_url}")
            logger.info(f"         ç¢¼ç‡: {rtsp_bitrate}kbps")
            logger.info(f"      â³ RTSP æ¨æµå°‡åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹•...")
            # ç¨å¾Œåœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
            self.rtsp_enabled = False
            self.rtsp_initialized = False
        else:
            if enable_rtsp:
                logger.warning(f"âš ï¸  RTSP å·²å•Ÿç”¨ä½† URL æœªè¨­å®š")
            self.rtsp_enabled = False
            self.rtsp_initialized = True

        # é›™ä¸²æµæ¨¡å¼ï¼ˆåƒ…åœ¨ dual_stream æ¨¡å¼ï¼‰
        self.server_right = None
        if stream_mode == "dual_stream" and dual_camera:
            self.server_right = StreamingServer(http_port=http_port + 1, fps=30)
            self.server_right.run(threaded=True)
            logger.info(f"      âœ“ å³å´ä¸²æµå·²å•Ÿå‹• (ç«¯å£ {http_port + 1})")

        logger.info("=" * 60)
        logger.info("ğŸ‰ ç³»çµ±å·²å®Œå…¨å•Ÿå‹•ï¼")
        logger.info("=" * 60)
        # ç”Ÿæˆè¨ªå•åœ°å€
        device_ip = config.device_ip or "[ä½ çš„IP]"
        local_url = f"http://{device_ip}:{http_port}"
        logger.info(f"ğŸ“± æœ¬æ©Ÿè¨ªå•: {local_url}")

        # å¦‚æœè¨­ç½®äº†å¤–éƒ¨ URLï¼Œé¡¯ç¤ºå¤–éƒ¨è¨ªå•æ–¹å¼
        if config.external_url:
            logger.info(f"ğŸŒ é ç«¯è¨ªå•: {config.external_url}")

        if self.server_right:
            right_url = f"http://{device_ip}:{http_port + 1}"
            logger.info(f"ğŸ“± å³å´è¦–è§’ï¼ˆæœ¬æ©Ÿï¼‰: {right_url}")

        logger.info("â„¹ï¸  ç³»çµ±é…ç½®:")
        logger.info(f"   - AI æª¢æ¸¬: âœ“ å•Ÿç”¨ ({self.detector.backend.upper()})")
        logger.info(f"   - é›²å°è¿½è¹¤: {'âœ“ å•Ÿç”¨' if self.has_pt else 'âœ— åœç”¨'}")
        logger.info(f"   - é›·å°„æ¨™è¨˜: {'âœ“ å•Ÿç”¨' if self.has_laser else 'âœ— åœç”¨'}")
        logger.info(f"   - æ·±åº¦ä¼°è¨ˆ: {'âœ“ å•Ÿç”¨' if self.enable_depth else 'âœ— åœç”¨'}")
        logger.info(f"   - æ¨£æœ¬å„²å­˜: {'âœ“ å•Ÿç”¨' if save_samples else 'âœ— åœç”¨'}")
        logger.info(f"   - é›™ç›®æ”åƒé ­: {'âœ“ å•Ÿç”¨' if dual_camera else 'âœ— åœç”¨'}")
        logger.info(f"   - ä¸²æµæ¨¡å¼: {stream_mode}")

        logger.info("âš¡ æ€§èƒ½èªªæ˜:")
        logger.info(f"   - AI è² è¼‰: æ¯å¹€åªåŸ·è¡Œä¸€æ¬¡æª¢æ¸¬")
        logger.info(f"   - è¨˜æ†¶é«”: å–®ä¸€æª¢æ¸¬å™¨å¯¦ä¾‹")
        logger.info(f"   - CPU: æœ€å„ªåŒ–åˆ©ç”¨")

        logger.info("ğŸ® æ§åˆ¶æ–¹å¼:")
        logger.info("   Ctrl+C - é€€å‡ºç³»çµ±")
        logger.info("   (é€šéç€è¦½å™¨è¨ªå• HTTP ä¸²æµæŸ¥çœ‹å½±åƒ)")

    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        è™•ç†å–®å¹€å½±åƒï¼ˆAI æª¢æ¸¬ + è¿½è¹¤ + æ¨™è¨»ï¼‰

        âš ï¸ é‡è¦ï¼šæ­¤å‡½æ•¸æ¯å¹€åªèª¿ç”¨ä¸€æ¬¡ AI æª¢æ¸¬ï¼Œä¸æœƒé‡è¤‡ï¼
        """
        self.stats['total_frames'] += 1

        # åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
        if self.enable_rtsp and not self.rtsp_initialized:
            h, w = frame.shape[:2]
            logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RTSP...")
            logger.info(f"   RTSP URL: {self.rtsp_url}")
            logger.info(f"   RTSP ç¢¼ç‡: {self.rtsp_bitrate}kbps")
            logger.info(f"   å¹€å°ºå¯¸: {w}x{h}")
            try:
                if self.server.enable_rtsp_push(w, h, bitrate=self.rtsp_bitrate):
                    logger.info("âœ… RTSP æ¨æµå·²å•Ÿå‹•")
                    self.rtsp_enabled = True
                else:
                    logger.warning("âš ï¸  RTSP æ¨æµå•Ÿå‹•è¿”å› False")
            except Exception as e:
                logger.error(f"âŒ RTSP åˆå§‹åŒ–å¤±æ•—: {e}")
                traceback.print_exc()
            finally:
                self.rtsp_initialized = True

        # åˆ†é›¢å·¦å³ç•«é¢ï¼ˆå¦‚æœæ˜¯é›™ç›®ï¼‰
        if self.dual_camera:
            height, width = frame.shape[:2]
            mid = width // 2
            left_frame = frame[:, :mid]
            right_frame = frame[:, mid:]

            # é¦–æ¬¡é‹è¡Œæ™‚åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆä½¿ç”¨å¯¦éš›è§£æåº¦ï¼‰
            if self.enable_depth and self.depth_estimator is None:
                single_width = left_frame.shape[1]
                logger.info(f"ğŸ”§ åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå–®çœ¼è§£æåº¦: {single_width}Ã—{left_frame.shape[0]}ï¼‰")
                self.depth_estimator = DepthEstimator(
                    focal_length=3.0,        # é¡é ­ç„¦è· 3.0mm
                    baseline=120.0,          # é›™ç›®åŸºç·š 12cm
                    image_width=single_width,  # ä½¿ç”¨å¯¦éš›å–®çœ¼è§£æåº¦
                    sensor_width=5.0         # æ„Ÿå…‰å…ƒä»¶å¯¬åº¦
                )
                logger.info(f"      âœ“ æ·±åº¦ä¼°è¨ˆå·²å•Ÿç”¨ï¼ˆæ¸¬è·ç¯„åœ: 0.5-5mï¼‰")
        else:
            left_frame = frame
            right_frame = None

        # âš¡ AI æª¢æ¸¬ï¼ˆæ¯å¹€åªåŸ·è¡Œä¸€æ¬¡ï¼ï¼‰
        # é›™ç›®æ¨¡å¼ï¼šå‘ŠçŸ¥æª¢æ¸¬å™¨é€™æ˜¯å·¦çœ¼ç•«é¢ï¼Œåªéæ¿¾ä¸Šä¸‹é‚Šç·£
        detections, result_left, illumination_info = self.detector.detect(left_frame, is_dual_left=self.dual_camera)

        # éæ¿¾ç•°å¸¸ä¿¡å¿ƒåº¦å€¼ï¼ˆæ’é™¤ confidence == 1.0 çš„ç•°å¸¸æª¢æ¸¬ï¼‰
        if detections:
            detections = [d for d in detections if d.get('confidence', 0) < 1.0]
            if len([d for d in detections if d.get('confidence', 0) >= 1.0]) > 0:
                logger.debug(f"å·²éæ¿¾ {len([d for d in detections if d.get('confidence', 0) >= 1.0])} å€‹ä¿¡å¿ƒåº¦=1.0çš„ç•°å¸¸æª¢æ¸¬")

        # è¿½è¹¤å”¯ä¸€ç›®æ¨™
        if detections:
            self._update_unique_targets(detections)

            # ğŸ¯ æ·±åº¦ä¼°è¨ˆèˆ‡å°ºå¯¸éæ¿¾ï¼ˆå¦‚æœå•Ÿç”¨ä¸”æœ‰å³çœ¼å½±åƒï¼‰
            if self.depth_estimator and right_frame is not None:
                valid_detections = []
                for detection in detections:
                    bbox = detection.get('bbox')
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        # ä¼°è¨ˆæ·±åº¦èˆ‡å¯¦éš›å°ºå¯¸
                        depth_info = self.depth_estimator.estimate_depth_for_detection(
                            left_frame, right_frame, (x1, y1, x2, y2)
                        )
                        if depth_info:
                            detection['depth'] = depth_info['depth']
                            detection['distance_cm'] = depth_info['distance_cm']
                            detection['object_size_mm'] = depth_info.get('object_size_mm', 0)

                            # å°ºå¯¸éæ¿¾ï¼šåªä¿ç•™åˆç†å°ºå¯¸çš„æª¢æ¸¬
                            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
                            obj_size = depth_info.get('object_size_mm', 0)
                            if config.min_mosquito_size_mm <= obj_size <= config.max_mosquito_size_mm:
                                valid_detections.append(detection)

                        else:
                            # ç„¡æ³•ä¼°è¨ˆæ·±åº¦æ™‚ä¿ç•™ï¼ˆé¿å…éåº¦éæ¿¾ï¼‰
                            valid_detections.append(detection)
                    else:
                        valid_detections.append(detection)

                # æ›´æ–°ç‚ºéæ¿¾å¾Œçš„æª¢æ¸¬çµæœ
                detections = valid_detections
            else:
                # å–®ç›®æ¨¡å¼æˆ–ç„¡æ·±åº¦ä¼°è¨ˆï¼šä½¿ç”¨åƒç´ ç´šéæ¿¾
                detections = self._apply_monocular_filters(detections)

        # è¿½è¹¤æ§åˆ¶ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.tracker and detections:
            self.tracker.update(detections)
            self.stats['tracking_active'] = True
        else:
            self.stats['tracking_active'] = False

        # å„²å­˜å…‰ç…§åº¦è³‡è¨Š
        self.stats['last_illumination_info'] = illumination_info

        # è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶è©³ç´°è³‡è¨Š
        if detections:
            self._log_detection_details(detections)

        # ç¹ªè£½ AI æ¨™è¨»ï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰
        result_left = self._draw_detections_with_depth(result_left, detections)

        # æ·»åŠ ç³»çµ±è³‡è¨Š
        self._draw_system_info(result_left, detections, illumination_info)

        # æ ¹æ“šä¸²æµæ¨¡å¼çµ„åˆç•«é¢
        if self.stream_mode == "side_by_side" and right_frame is not None:
            # ä¸¦æ’é¡¯ç¤º
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            combined = np.hstack([result_left, right_frame])
            # æ·»åŠ åˆ†éš”ç·š
            mid = combined.shape[1] // 2
            cv2.line(combined, (mid, 0), (mid, combined.shape[0]),
                    (0, 255, 255), 2)
            return combined

        elif self.stream_mode == "dual_stream" and right_frame is not None:
            # é›™ä¸²æµæ¨¡å¼
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            return result_left, right_frame

        else:
            # å–®ä¸€è¦–è§’
            return result_left

    def _draw_detections_with_depth(self, frame: np.ndarray, detections: list) -> np.ndarray:
        """
        ç¹ªè£½æª¢æ¸¬çµæœï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰

        Args:
            frame: å½±åƒå¹€
            detections: æª¢æ¸¬çµæœåˆ—è¡¨

        Returns:
            æ¨™è¨»å¾Œçš„å½±åƒ
        """
        # å…ˆç¹ªè£½åŸºæœ¬æª¢æ¸¬æ¡†
        frame = self.detector.draw_detections(frame, detections)

        # å¦‚æœå•Ÿç”¨æ·±åº¦ä¼°è¨ˆï¼Œæ·»åŠ æ·±åº¦è³‡è¨Š
        if self.depth_estimator and detections:
            for detection in detections:
                bbox = detection.get('bbox')
                depth = detection.get('depth')
                distance_cm = detection.get('distance_cm')

                if bbox and distance_cm:
                    x1, y1, x2, y2 = bbox
                    obj_size = detection.get('object_size_mm', 0)

                    # åœ¨æª¢æ¸¬æ¡†ä¸‹æ–¹é¡¯ç¤ºè·é›¢èˆ‡å°ºå¯¸è³‡è¨Š
                    if obj_size > 0:
                        distance_text = f"{distance_cm:.1f}cm | {obj_size:.1f}mm"
                    else:
                        distance_text = f"{distance_cm:.1f}cm"
                    text_size = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    text_x = x1
                    text_y = y2 + 25

                    # ç¹ªè£½èƒŒæ™¯
                    cv2.rectangle(frame,
                                (text_x, text_y - text_size[1] - 5),
                                (text_x + text_size[0] + 5, text_y + 5),
                                (0, 0, 0), -1)

                    # ç¹ªè£½è·é›¢èˆ‡å°ºå¯¸æ–‡å­—ï¼ˆæ©™è‰²ï¼‰
                    cv2.putText(frame, distance_text,
                              (text_x + 2, text_y),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)

        return frame

    def _update_unique_targets(self, detections: list):
        """æ›´æ–°å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰"""
        current_time = time.time()

        # æ¨™è¨˜æ‰€æœ‰è¿½è¹¤ç‚ºã€Œå¯èƒ½æ¶ˆå¤±ã€
        for track_id in self.active_tracks:
            self.active_tracks[track_id]['lost_frames'] += 1

        # ç‚ºæ¯å€‹æª¢æ¸¬åˆ†é…æˆ–åŒ¹é…è¿½è¹¤ID
        for detection in detections:
            center = detection.get('center', (0, 0))
            matched_track_id = None
            min_distance = self.track_distance_threshold

            # å°‹æ‰¾æœ€è¿‘çš„ç¾æœ‰è¿½è¹¤
            for track_id, track_info in self.active_tracks.items():
                if track_info['lost_frames'] > self.track_lost_frames_max:
                    continue  # å·²æ¶ˆå¤±çš„è¿½è¹¤ä¸åŒ¹é…

                track_center = track_info['center']
                distance = np.sqrt((center[0] - track_center[0])**2 +
                                 (center[1] - track_center[1])**2)

                if distance < min_distance:
                    min_distance = distance
                    matched_track_id = track_id

            # æ›´æ–°æˆ–å‰µå»ºè¿½è¹¤
            if matched_track_id is not None:
                # åŒ¹é…åˆ°ç¾æœ‰è¿½è¹¤
                self.active_tracks[matched_track_id]['center'] = center
                self.active_tracks[matched_track_id]['last_seen'] = current_time
                self.active_tracks[matched_track_id]['lost_frames'] = 0
                detection['track_id'] = matched_track_id
            else:
                # æ–°ç›®æ¨™
                new_track_id = self.next_track_id
                self.next_track_id += 1
                self.active_tracks[new_track_id] = {
                    'center': center,
                    'last_seen': current_time,
                    'lost_frames': 0
                }
                self.stats['unique_targets'] += 1
                detection['track_id'] = new_track_id

        # æ¸…ç†é•·æ™‚é–“æœªè¦‹çš„è¿½è¹¤
        tracks_to_remove = [
            track_id for track_id, track_info in self.active_tracks.items()
            if track_info['lost_frames'] > self.track_lost_frames_max
        ]
        for track_id in tracks_to_remove:
            del self.active_tracks[track_id]
            # æ¸…ç†å–®ç›®éæ¿¾å™¨æ­·å²æ•¸æ“š
            if track_id in self.detection_history:
                del self.detection_history[track_id]

    def _apply_monocular_filters(self, detections: list) -> list:
        """
        å–®ç›®æ¨¡å¼éæ¿¾å™¨ï¼ˆç„¡æ·±åº¦è³‡è¨Šæ™‚ä½¿ç”¨ï¼‰
        åŒ…å«ï¼šæª¢æ¸¬æ¡†å¤§å°ã€å¯¬é«˜æ¯”ã€æ™‚é–“é€£çºŒæ€§ã€é‹å‹•åˆç†æ€§
        """
        # å¾é…ç½®åŠ è¼‰ç¯©é¸åƒæ•¸
        try:
            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
            ENABLE_BBOX_SIZE_FILTER = config.enable_bbox_size_filter
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            ENABLE_ASPECT_RATIO_FILTER = config.enable_aspect_ratio_filter
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
            ENABLE_TEMPORAL_FILTER = config.enable_temporal_filter
            MIN_CONSECUTIVE_FRAMES = config.min_consecutive_frames
            ENABLE_MOTION_FILTER = config.enable_motion_filter
            MAX_MOVEMENT_PX_PER_FRAME = config.max_movement_px_per_frame
            MAX_STATIC_FRAMES = config.max_static_frames
            STATIC_THRESHOLD_PX = config.static_threshold_px
        except ImportError:
            # é»˜èªå€¼
            ENABLE_BBOX_SIZE_FILTER = True
            MIN_BBOX_SIZE_PX = 10
            MAX_BBOX_SIZE_PX = 200
            ENABLE_ASPECT_RATIO_FILTER = True
            MIN_ASPECT_RATIO = 0.3
            MAX_ASPECT_RATIO = 3.0
            ENABLE_TEMPORAL_FILTER = True
            MIN_CONSECUTIVE_FRAMES = 3
            ENABLE_MOTION_FILTER = True
            MAX_MOVEMENT_PX_PER_FRAME = 150
            MAX_STATIC_FRAMES = 60
            STATIC_THRESHOLD_PX = 5

        valid_detections = []

        for detection in detections:
            bbox = detection.get('bbox')
            if not bbox:
                continue

            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            center = detection.get('center', ((x1+x2)//2, (y1+y2)//2))
            track_id = detection.get('track_id')

            # 1. æª¢æ¸¬æ¡†å¤§å°éæ¿¾
            if ENABLE_BBOX_SIZE_FILTER:
                size = max(width, height)
                if size < MIN_BBOX_SIZE_PX or size > MAX_BBOX_SIZE_PX:
                    logger.debug(f"æ¡†å¤§å°éæ¿¾: {size}px ä¸åœ¨ {MIN_BBOX_SIZE_PX}-{MAX_BBOX_SIZE_PX}px ç¯„åœ")
                    continue

            # 2. å¯¬é«˜æ¯”éæ¿¾
            if ENABLE_ASPECT_RATIO_FILTER:
                aspect_ratio = width / max(height, 1)
                if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
                    logger.debug(f"å¯¬é«˜æ¯”éæ¿¾: {aspect_ratio:.2f} ä¸åœ¨ {MIN_ASPECT_RATIO}-{MAX_ASPECT_RATIO} ç¯„åœ")
                    continue

            # 3. æ™‚é–“é€£çºŒæ€§éæ¿¾
            if ENABLE_TEMPORAL_FILTER and track_id is not None:
                if track_id not in self.detection_history:
                    self.detection_history[track_id] = {
                        'frames': 1,
                        'positions': self._deque_cls(maxlen=10),
                        'static_frames': 0
                    }
                    self.detection_history[track_id]['positions'].append(center)
                else:
                    self.detection_history[track_id]['frames'] += 1
                    self.detection_history[track_id]['positions'].append(center)

                # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å°‘å¹€æ•¸
                if self.detection_history[track_id]['frames'] < MIN_CONSECUTIVE_FRAMES:
                    logger.debug(f"æ™‚é–“é€£çºŒæ€§éæ¿¾: track_{track_id} åƒ…å‡ºç¾ {self.detection_history[track_id]['frames']} å¹€")
                    continue

            # 4. é‹å‹•åˆç†æ€§éæ¿¾
            if ENABLE_MOTION_FILTER and track_id is not None and track_id in self.detection_history:
                history = self.detection_history[track_id]
                positions = history['positions']

                if len(positions) >= 2:
                    prev_pos = positions[-2]
                    curr_pos = center
                    movement = np.sqrt((curr_pos[0] - prev_pos[0])**2 + (curr_pos[1] - prev_pos[1])**2)

                    # ç§»å‹•éå¿«éæ¿¾
                    if movement > MAX_MOVEMENT_PX_PER_FRAME:
                        logger.debug(f"é‹å‹•éå¿«éæ¿¾: track_{track_id} ç§»å‹• {movement:.1f}px > {MAX_MOVEMENT_PX_PER_FRAME}px")
                        continue

                    # éœæ­¢éä¹…éæ¿¾
                    if movement < STATIC_THRESHOLD_PX:
                        history['static_frames'] += 1
                        if history['static_frames'] > MAX_STATIC_FRAMES:
                            logger.debug(f"éœæ­¢éä¹…éæ¿¾: track_{track_id} éœæ­¢ {history['static_frames']} å¹€")
                            continue
                    else:
                        history['static_frames'] = 0

            # é€šéæ‰€æœ‰éæ¿¾å™¨
            valid_detections.append(detection)

        return valid_detections

    def _log_detection_details(self, detections: list):
        """è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶çš„è©³ç´°è³‡è¨Š"""
        # å¾é…ç½®åŠ è¼‰ç‰©ç†åƒæ•¸
        try:
            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
            MIN_MOSQUITO_SIZE_MM = config.min_mosquito_size_mm
            MAX_MOSQUITO_SIZE_MM = config.max_mosquito_size_mm
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
        except ImportError:
            # é»˜èªå€¼
            MIN_MOSQUITO_SIZE_MM = 3
            MAX_MOSQUITO_SIZE_MM = 15


    def run(self):
        """é‹è¡Œç³»çµ±ä¸»å¾ªç’°"""
        # åˆå§‹åŒ–æ”åƒé ­
        cap = cv2.VideoCapture(self.camera_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
        cap.set(cv2.CAP_PROP_FPS, self.camera_fps)

        if not cap.isOpened():
            logger.error(f"âŒ ç„¡æ³•æ‰“é–‹æ”åƒé ­ {self.camera_id}")
            return

        logger.info(f"ğŸ¥ æ”åƒé ­å·²æ‰“é–‹: {self.camera_width}x{self.camera_height}@{self.camera_fps}fps")

        try:
            frame_count = 0
            start_time = time.time()

            while self._running:
                ret, frame = cap.read()
                if not ret:
                    logger.error("âŒ ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                    break

                # è™•ç†å½±åƒå¹€
                processed_frame = self.process_frame(frame)

                # ç™¼é€åˆ°ä¸²æµä¼ºæœå™¨
                if self.stream_mode == "dual_stream" and isinstance(processed_frame, tuple):
                    left_frame, right_frame = processed_frame
                    self.server.push_frame(left_frame)
                    if self.server_right:
                        self.server_right.push_frame(right_frame)
                else:
                    # çµ±ä¸€è™•ç†æ‰€æœ‰é dual_stream æ¨¡å¼çš„æƒ…æ³
                    self.server.push_frame(processed_frame)

                frame_count += 1

                # æ¯100å¹€è¼¸å‡ºä¸€æ¬¡çµ±è¨ˆè³‡è¨Š
                if frame_count % 100 == 0:
                    elapsed_time = time.time() - start_time
                    fps = 100 / elapsed_time if elapsed_time > 0 else 0
                    logger.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š: {fps:.1f} FPS, "
                               f"ç¸½å¹€æ•¸: {frame_count}, "
                               f"å”¯ä¸€ç›®æ¨™: {self.stats['unique_targets']}, "
                               f"è¿½è¹¤ç‹€æ…‹: {'ğŸŸ¢' if self.stats['tracking_active'] else 'ğŸ”´'}")
                    start_time = time.time()

        except Exception as e:
            logger.error(f"âŒ ç³»çµ±é‹è¡Œç•°å¸¸: {e}")
            traceback.print_exc()
        finally:
            cap.release()
            logger.info("ğŸ“¹ æ”åƒé ­å·²é‡‹æ”¾")


    def stop(self):
        """åœæ­¢ç³»çµ±"""
        logger.info("ğŸ›‘ åœæ­¢ç³»çµ±...")
        self._running = False


def signal_handler(sig, frame):
    """ä¿¡è™Ÿè™•ç†å™¨ï¼Œç”¨æ–¼å„ªé›…é€€å‡º"""
    logger.info('\nğŸ‘‹ æ”¶åˆ°é€€å‡ºä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰ç³»çµ±...')
    if 'system' in locals():
        system.stop()


def main():
    parser = argparse.ArgumentParser(description='ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµæ•´åˆ')
    parser.add_argument('--port', '-p', type=str, default=config.arduino_port,
                       help='Arduino ä¸²å£ (é è¨­: config.arduino_port)')
    parser.add_argument('--camera', '-c', type=int, default=config.left_camera_id,
                       help='æ”åƒé ­ ID (é è¨­: config.left_camera_id)')
    parser.add_argument('--model', type=str, default="models/mosquito",
                       help='AI æ¨¡å‹è·¯å¾‘ (é è¨­: models/mosquito)')
    parser.add_argument('--single', action='store_true',
                       help='å¼·åˆ¶å–®ç›®æ”åƒé ­æ¨¡å¼')
    parser.add_argument('--dual', action='store_true',
                       help='å¼·åˆ¶é›™ç›®æ”åƒé ­æ¨¡å¼')
    parser.add_argument('--mode', '-m', type=str, default="single",
                       choices=["single", "side_by_side", "dual_stream"],
                       help='ä¸²æµæ¨¡å¼ (é è¨­: single)')
    parser.add_argument('--port-http', type=int, default=config.stream_port,
                       help='HTTP ä¸²æµç«¯å£ (é è¨­: config.stream_port)')
    parser.add_argument('--save-samples', action='store_true',
                       help='å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬')
    parser.add_argument('--no-save-samples', dest='save_samples', action='store_false',
                       help='ä¸å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬')
    parser.set_defaults(save_samples=config.save_uncertain_samples)
    parser.add_argument('--rtsp', action='store_true',
                       help='å•Ÿç”¨ RTSP æ¨æµ')
    parser.add_argument('--rtsp-url', type=str, default=config.rtsp_url,
                       help='RTSP æ¨æµåœ°å€')
    parser.add_argument('--rtsp-bitrate', type=int, default=2000,
                       help='RTSP ç¢¼ç‡ (kbps, é è¨­: 2000)')

    args = parser.parse_args()

    # ç¢ºå®šæ”åƒé ­æ¨¡å¼
    dual_camera = args.dual or (not args.single and config.camera_dual_width > 1920)
    if args.single:
        logger.info(f"ğŸ“· å¼·åˆ¶ä½¿ç”¨å–®ç›®æ”åƒé ­æ¨¡å¼")
    elif args.dual:
        logger.info(f"ğŸ“· å¼·åˆ¶ä½¿ç”¨é›™ç›®æ”åƒé ­æ¨¡å¼")
    else:
        logger.info(f"ğŸ“· è‡ªå‹•æª¢æ¸¬æ”åƒé ­æ¨¡å¼: {'é›™ç›®' if dual_camera else 'å–®ç›®'}")

    # è¨­ç½®ä¿¡è™Ÿè™•ç†å™¨ä»¥å„ªé›…é€€å‡º
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # åˆå§‹åŒ–ç³»çµ±
    system = StreamingTrackingSystem(
        arduino_port=args.port,
        camera_id=args.camera,
        model_path=args.model,
        http_port=args.port_http,
        dual_camera=dual_camera,
        stream_mode=args.mode,
        save_samples=args.save_samples,
        enable_depth=dual_camera,  # æ·±åº¦ä¼°è¨ˆéœ€è¦é›™ç›®æ”åƒé ­
        enable_rtsp=args.rtsp,
        rtsp_url=args.rtsp_url,
        rtsp_bitrate=args.rtsp_bitrate
    )

    # é‹è¡Œç³»çµ±
    logger.info("ğŸš€ ç³»çµ±é–‹å§‹é‹è¡Œ... æŒ‰ Ctrl+C é€€å‡º")
    try:
        system.run()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ä½¿ç”¨è€…ä¸­æ–·ï¼Œæ­£åœ¨é—œé–‰ç³»çµ±...")
    except Exception as e:
        logger.error(f"ç³»çµ±é‹è¡ŒéŒ¯èª¤: {e}")
        traceback.print_exc()
    finally:
        system.stop()
        logger.info("âœ… ç³»çµ±å·²é—œé–‰")


if __name__ == "__main__":
    main()