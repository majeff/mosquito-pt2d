"""
å®Œæ•´èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµ
æ•´åˆ AI æª¢æ¸¬ã€é›²å°è¿½è¹¤ã€å½±åƒä¸²æµæ–¼ä¸€é«”

âš ï¸ é€™æ˜¯å”¯ä¸€éœ€è¦é‹è¡Œçš„ç¨‹å¼ï¼
- âœ… åŒ…å« AI æª¢æ¸¬ (MosquitoDetector)
- âœ… åŒ…å«é›²å°æ§åˆ¶ (PT2DController)
- âœ… åŒ…å«è¿½è¹¤é‚è¼¯ (MosquitoTracker)
- âœ… åŒ…å«å½±åƒä¸²æµ (StreamingServer)
- âœ… AI è² è¼‰ä¸æœƒé‡è¤‡ï¼ˆæ¯å¹€åªæª¢æ¸¬ä¸€æ¬¡ï¼‰
- âœ… æ”¯æ´é›™ç›®æ”åƒé ­

ä½¿ç”¨æ–¹å¼ï¼š
    python streaming_tracking_system.py
"""

# Copyright 2025 Arduino PT2D Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from streaming_server import StreamingServer
from mosquito_detector import MosquitoDetector
from mosquito_tracker import MosquitoTracker
from pt2d_controller import PT2DController
from depth_estimator import DepthEstimator
from config import (DEFAULT_CONFIDENCE_THRESHOLD, DEFAULT_IMGSZ,
                   DEFAULT_DEVICE_IP, DEFAULT_EXTERNAL_URL,
                   DEFAULT_MAX_SAMPLES, DEFAULT_SAVE_INTERVAL,
                   DEFAULT_SAVE_UNCERTAIN_SAMPLES, DEFAULT_UNCERTAIN_CONF_RANGE,
                   SAMPLE_COLLECTION_DIR,
                   CAMERA_DUAL_WIDTH, CAMERA_DUAL_HEIGHT, CAMERA_DUAL_FPS,
                   FRAME_DELAY)
import sys
import cv2
import numpy as np
import time
import argparse
import signal
import logging
import traceback
from pathlib import Path

# é…ç½® logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class StreamingTrackingSystem:
    """æ•´åˆçš„èšŠå­è¿½è¹¤èˆ‡ä¸²æµç³»çµ±"""

    def __init__(self,
                 arduino_port: str = '/dev/ttyUSB0',
                 camera_id: int = 0,
                 model_path: str = "models/mosquito",
                 http_port: int = 5000,
                 dual_camera: bool = True,
                 stream_mode: str = "single",
                 save_samples: bool = DEFAULT_SAVE_UNCERTAIN_SAMPLES,
                 sample_conf_range: tuple = DEFAULT_UNCERTAIN_CONF_RANGE,
                 enable_depth: bool = True,
                 enable_rtsp: bool = False,
                 rtsp_url: str = None,
                 rtsp_bitrate: int = 2000):
        """
        åˆå§‹åŒ–å®Œæ•´ç³»çµ±

        Args:
            arduino_port: Arduino ä¸²å£
            camera_id: æ”åƒé ­ ID
            model_path: AI æ¨¡å‹è·¯å¾‘
            http_port: HTTP ä¸²æµç«¯å£
            dual_camera: æ˜¯å¦ç‚ºé›™ç›®æ”åƒé ­
            stream_mode: ä¸²æµæ¨¡å¼ ("side_by_side", "single", "dual_stream")
            save_samples: æ˜¯å¦å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬
            sample_conf_range: æ¨£æœ¬ä¿¡å¿ƒåº¦ç¯„åœ (min, max)
            enable_depth: æ˜¯å¦å•Ÿç”¨æ·±åº¦ä¼°è¨ˆ
            enable_rtsp: æ˜¯å¦å•Ÿç”¨ RTSP æ¨æµ
            rtsp_url: RTSP æ¨æµåœ°å€
            rtsp_bitrate: RTSP è¦–é »ç¢¼ç‡ (kbps)
        """
        logger.info("=" * 60)
        logger.info("ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµæ•´åˆå•Ÿå‹•")
        logger.info("=" * 60)

        # ç³»çµ±é…ç½®
        self.dual_camera = dual_camera
        self.stream_mode = stream_mode
        self.camera_id = camera_id
        self.enable_depth = enable_depth and dual_camera  # æ·±åº¦ä¼°è¨ˆéœ€è¦é›™ç›®æ”åƒé ­
        self._running = True  # é‹è¡Œæ¨™èªŒï¼Œç”¨æ–¼å„ªé›…é€€å‡º

        # æ”åƒé ­è§£æåº¦é…ç½®ï¼ˆé è¨­å€¼ï¼Œæœƒåœ¨ main() ä¸­è¢«è¦†è“‹ï¼‰
        self.camera_width = CAMERA_DUAL_WIDTH if dual_camera else 1920
        self.camera_height = CAMERA_DUAL_HEIGHT if dual_camera else 1080
        self.camera_fps = CAMERA_DUAL_FPS if dual_camera else 60

        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total_frames': 0,
            'unique_targets': 0,          # å”¯ä¸€ç›®æ¨™æ•¸ï¼ˆå»é‡å¾Œï¼‰
            'tracking_active': False,
            'samples_saved': 0,
            'start_time': time.time(),
            'last_illumination_info': {}
        }

        # å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰
        self.active_tracks = {}           # {track_id: {'last_seen': time, 'center': (x,y), 'lost_frames': int}}
        self.next_track_id = 1
        self.track_distance_threshold = 100  # åƒç´ è·é›¢é–¾å€¼ï¼ˆ<100èªç‚ºæ˜¯åŒä¸€ç›®æ¨™ï¼‰
        self.track_lost_frames_max = 30     # è¶…é30å¹€æœªè¦‹è¦–ç‚ºæ¶ˆå¤±

        # å–®ç›®éæ¿¾å™¨è¿½è¹¤æ•¸æ“šï¼ˆç”¨æ–¼æ™‚é–“é€£çºŒæ€§å’Œé‹å‹•åˆç†æ€§æª¢æŸ¥ï¼‰
        self.detection_history = {}       # {track_id: {'frames': int, 'positions': deque, 'static_frames': int}}
        from collections import deque

        # 1. åˆå§‹åŒ– AI æª¢æ¸¬å™¨ï¼ˆåªå‰µå»ºä¸€æ¬¡ï¼ï¼‰
        logger.info("[1/5] åˆå§‹åŒ– AI æª¢æ¸¬å™¨...")
        self.detector = MosquitoDetector(
            model_path=model_path,
            confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,
            imgsz=DEFAULT_IMGSZ,
            save_uncertain_samples=save_samples,
            uncertain_conf_range=sample_conf_range,
            save_dir=SAMPLE_COLLECTION_DIR,
            max_samples=DEFAULT_MAX_SAMPLES,
            save_interval=DEFAULT_SAVE_INTERVAL,
            save_annotations=True,
            save_full_frame=False
        )
        logger.info(f"      âœ“ ä½¿ç”¨ {self.detector.backend.upper()} å¾Œç«¯")
        if save_samples:
            logger.info(f"      âœ“ æ¨£æœ¬å„²å­˜å·²å•Ÿç”¨ (ä¿¡å¿ƒåº¦ {sample_conf_range[0]}-{sample_conf_range[1]})")

        # 2. åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨
        logger.info("[2/5] åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨...")
        try:
            self.pt_controller = PT2DController(arduino_port)
            if self.pt_controller.is_connected:
                logger.info(f"      âœ“ Arduino å·²é€£æ¥ ({arduino_port})")
                self.has_pt = True
                self.has_laser = True  # é›²å°é€£æ¥æˆåŠŸæ™‚å•Ÿç”¨é›·å°„åŠŸèƒ½
            else:
                logger.warning(f"      âš  ç„¡æ³•é€£æ¥ Arduinoï¼Œåƒ…é‹è¡Œæª¢æ¸¬æ¨¡å¼")
                self.has_pt = False
                self.has_laser = False
        except Exception as e:
            logger.warning(f"      âš  é›²å°åˆå§‹åŒ–å¤±æ•—: {e}")
            self.has_pt = False
            self.has_laser = False
            self.pt_controller = None

        # 3. åˆå§‹åŒ–è¿½è¹¤å™¨
        logger.info("[3/5] åˆå§‹åŒ–è¿½è¹¤å™¨...")
        if self.has_pt:
            self.tracker = MosquitoTracker(
                detector=self.detector,
                pt_controller=self.pt_controller
            )
            logger.info(f"      âœ“ è¿½è¹¤å™¨å·²å°±ç·’")
        else:
            self.tracker = None
            logger.warning(f"      âš  è¿½è¹¤å™¨æœªå•Ÿç”¨ï¼ˆéœ€è¦é›²å°é€£æ¥ï¼‰")

        # 4. åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        logger.info("[4/6] åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨...")
        if self.enable_depth:
            # æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨ run() ä¸­æ ¹æ“šå¯¦éš›è§£æåº¦åˆå§‹åŒ–
            self.depth_estimator = None
            logger.info(f"      â³ æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨é¦–å¹€æ™‚åˆå§‹åŒ–ï¼ˆæ ¹æ“šå¯¦éš›è§£æåº¦ï¼‰")
        else:
            self.depth_estimator = None
            logger.info(f"      âš  æ·±åº¦ä¼°è¨ˆæœªå•Ÿç”¨ï¼ˆéœ€è¦é›™ç›®æ”åƒé ­ï¼‰")

        # 5. åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨
        logger.info("[5/6] åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨...")
        self.server = StreamingServer(
            http_port=http_port,
            fps=30,
            rtsp_url=rtsp_url if enable_rtsp else None
        )
        self.server.run(threaded=True)
        logger.info(f"      âœ“ ä¸²æµä¼ºæœå™¨å·²å•Ÿå‹• (ç«¯å£ {http_port})")

        # 6. åˆå§‹åŒ– RTSP æ¨æµï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        self.enable_rtsp = enable_rtsp
        self.rtsp_url = rtsp_url
        self.rtsp_bitrate = rtsp_bitrate
        if enable_rtsp and rtsp_url:
            logger.info("[6/6] åˆå§‹åŒ– RTSP æ¨æµ...")
            logger.info(f"      âœ“ RTSP å·²é…ç½®")
            logger.info(f"         URL: {rtsp_url}")
            logger.info(f"         ç¢¼ç‡: {rtsp_bitrate}kbps")
            logger.info(f"      â³ RTSP æ¨æµå°‡åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹•...")
            # ç¨å¾Œåœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
            self.rtsp_enabled = False
            self.rtsp_initialized = False
        else:
            if enable_rtsp:
                logger.warning(f"âš ï¸  RTSP å·²å•Ÿç”¨ä½† URL æœªè¨­å®š")
            self.rtsp_enabled = False
            self.rtsp_initialized = True

        # é›™ä¸²æµæ¨¡å¼ï¼ˆåƒ…åœ¨ dual_stream æ¨¡å¼ï¼‰
        self.server_right = None
        if stream_mode == "dual_stream" and dual_camera:
            self.server_right = StreamingServer(http_port=http_port + 1, fps=30)
            self.server_right.run(threaded=True)
            logger.info(f"      âœ“ å³å´ä¸²æµå·²å•Ÿå‹• (ç«¯å£ {http_port + 1})")

        logger.info("=" * 60)
        logger.info("ğŸ‰ ç³»çµ±å·²å®Œå…¨å•Ÿå‹•ï¼")
        logger.info("=" * 60)
        # ç”Ÿæˆè¨ªå•åœ°å€
        device_ip = DEFAULT_DEVICE_IP or "[ä½ çš„IP]"
        local_url = f"http://{device_ip}:{http_port}"
        logger.info(f"ğŸ“± æœ¬æ©Ÿè¨ªå•: {local_url}")

        # å¦‚æœè¨­ç½®äº†å¤–éƒ¨ URLï¼Œé¡¯ç¤ºå¤–éƒ¨è¨ªå•æ–¹å¼
        if DEFAULT_EXTERNAL_URL:
            logger.info(f"ğŸŒ é ç«¯è¨ªå•: {DEFAULT_EXTERNAL_URL}")

        if self.server_right:
            right_url = f"http://{device_ip}:{http_port + 1}"
            logger.info(f"ğŸ“± å³å´è¦–è§’ï¼ˆæœ¬æ©Ÿï¼‰: {right_url}")

        logger.info("â„¹ï¸  ç³»çµ±é…ç½®:")
        logger.info(f"   - AI æª¢æ¸¬: âœ“ å•Ÿç”¨ ({self.detector.backend.upper()})")
        logger.info(f"   - é›²å°è¿½è¹¤: {'âœ“ å•Ÿç”¨' if self.has_pt else 'âœ— åœç”¨'}")
        logger.info(f"   - é›·å°„æ¨™è¨˜: {'âœ“ å•Ÿç”¨' if self.has_laser else 'âœ— åœç”¨'}")
        logger.info(f"   - æ·±åº¦ä¼°è¨ˆ: {'âœ“ å•Ÿç”¨' if self.enable_depth else 'âœ— åœç”¨'}")
        logger.info(f"   - æ¨£æœ¬å„²å­˜: {'âœ“ å•Ÿç”¨' if save_samples else 'âœ— åœç”¨'}")
        logger.info(f"   - é›™ç›®æ”åƒé ­: {'âœ“ å•Ÿç”¨' if dual_camera else 'âœ— åœç”¨'}")
        logger.info(f"   - ä¸²æµæ¨¡å¼: {stream_mode}")

        logger.info("âš¡ æ€§èƒ½èªªæ˜:")
        logger.info(f"   - AI è² è¼‰: æ¯å¹€åªåŸ·è¡Œä¸€æ¬¡æª¢æ¸¬")
        logger.info(f"   - è¨˜æ†¶é«”: å–®ä¸€æª¢æ¸¬å™¨å¯¦ä¾‹")
        logger.info(f"   - CPU: æœ€å„ªåŒ–åˆ©ç”¨")

        logger.info("ğŸ® æ§åˆ¶æ–¹å¼:")
        logger.info("   Ctrl+C - é€€å‡ºç³»çµ±")
        logger.info("   (é€šéç€è¦½å™¨è¨ªå• HTTP ä¸²æµæŸ¥çœ‹å½±åƒ)")

    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        è™•ç†å–®å¹€å½±åƒï¼ˆAI æª¢æ¸¬ + è¿½è¹¤ + æ¨™è¨»ï¼‰

        âš ï¸ é‡è¦ï¼šæ­¤å‡½æ•¸æ¯å¹€åªèª¿ç”¨ä¸€æ¬¡ AI æª¢æ¸¬ï¼Œä¸æœƒé‡è¤‡ï¼
        """
        self.stats['total_frames'] += 1

        # åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
        if self.enable_rtsp and not self.rtsp_initialized:
            h, w = frame.shape[:2]
            logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RTSP...")
            logger.info(f"   RTSP URL: {self.rtsp_url}")
            logger.info(f"   RTSP ç¢¼ç‡: {self.rtsp_bitrate}kbps")
            logger.info(f"   å¹€å°ºå¯¸: {w}x{h}")
            try:
                if self.server.enable_rtsp_push(w, h, bitrate=self.rtsp_bitrate):
                    logger.info("âœ… RTSP æ¨æµå·²å•Ÿå‹•")
                    self.rtsp_enabled = True
                else:
                    logger.warning("âš ï¸  RTSP æ¨æµå•Ÿå‹•è¿”å› False")
            except Exception as e:
                logger.error(f"âŒ RTSP åˆå§‹åŒ–å¤±æ•—: {e}")
                traceback.print_exc()
            finally:
                self.rtsp_initialized = True

        # åˆ†é›¢å·¦å³ç•«é¢ï¼ˆå¦‚æœæ˜¯é›™ç›®ï¼‰
        if self.dual_camera:
            height, width = frame.shape[:2]
            mid = width // 2
            left_frame = frame[:, :mid]
            right_frame = frame[:, mid:]

            # é¦–æ¬¡é‹è¡Œæ™‚åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆä½¿ç”¨å¯¦éš›è§£æåº¦ï¼‰
            if self.enable_depth and self.depth_estimator is None:
                single_width = left_frame.shape[1]
                logger.info(f"ğŸ”§ åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå–®çœ¼è§£æåº¦: {single_width}Ã—{left_frame.shape[0]}ï¼‰")
                self.depth_estimator = DepthEstimator(
                    focal_length=3.0,        # é¡é ­ç„¦è· 3.0mm
                    baseline=120.0,          # é›™ç›®åŸºç·š 12cm
                    image_width=single_width,  # ä½¿ç”¨å¯¦éš›å–®çœ¼è§£æåº¦
                    sensor_width=5.0         # æ„Ÿå…‰å…ƒä»¶å¯¬åº¦
                )
                logger.info(f"      âœ“ æ·±åº¦ä¼°è¨ˆå·²å•Ÿç”¨ï¼ˆæ¸¬è·ç¯„åœ: 0.5-5mï¼‰")
        else:
            left_frame = frame
            right_frame = None

        # âš¡ AI æª¢æ¸¬ï¼ˆæ¯å¹€åªåŸ·è¡Œä¸€æ¬¡ï¼ï¼‰
        # é›™ç›®æ¨¡å¼ï¼šå‘ŠçŸ¥æª¢æ¸¬å™¨é€™æ˜¯å·¦çœ¼ç•«é¢ï¼Œåªéæ¿¾ä¸Šä¸‹é‚Šç·£
        detections, result_left, illumination_info = self.detector.detect(left_frame, is_dual_left=self.dual_camera)

        # éæ¿¾ç•°å¸¸ä¿¡å¿ƒåº¦å€¼ï¼ˆæ’é™¤ confidence == 1.0 çš„ç•°å¸¸æª¢æ¸¬ï¼‰
        if detections:
            detections = [d for d in detections if d.get('confidence', 0) < 1.0]
            if len([d for d in detections if d.get('confidence', 0) >= 1.0]) > 0:
                logger.debug(f"å·²éæ¿¾ {len([d for d in detections if d.get('confidence', 0) >= 1.0])} å€‹ä¿¡å¿ƒåº¦=1.0çš„ç•°å¸¸æª¢æ¸¬")

        # è¿½è¹¤å”¯ä¸€ç›®æ¨™
        if detections:
            self._update_unique_targets(detections)

            # ğŸ¯ æ·±åº¦ä¼°è¨ˆèˆ‡å°ºå¯¸éæ¿¾ï¼ˆå¦‚æœå•Ÿç”¨ä¸”æœ‰å³çœ¼å½±åƒï¼‰
            if self.depth_estimator and right_frame is not None:
                valid_detections = []
                for detection in detections:
                    bbox = detection.get('bbox')
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        # ä¼°è¨ˆæ·±åº¦èˆ‡å¯¦éš›å°ºå¯¸
                        depth_info = self.depth_estimator.estimate_depth_for_detection(
                            left_frame, right_frame, (x1, y1, x2, y2)
                        )
                        if depth_info:
                            detection['depth'] = depth_info['depth']
                            detection['distance_cm'] = depth_info['distance_cm']
                            detection['object_size_mm'] = depth_info.get('object_size_mm', 0)

                            # å°ºå¯¸éæ¿¾ï¼šåªä¿ç•™åˆç†å°ºå¯¸çš„æª¢æ¸¬
                            from config import MIN_MOSQUITO_SIZE_MM, MAX_MOSQUITO_SIZE_MM
                            obj_size = depth_info.get('object_size_mm', 0)
                            if MIN_MOSQUITO_SIZE_MM <= obj_size <= MAX_MOSQUITO_SIZE_MM:
                                valid_detections.append(detection)
                            else:
                                logger.debug(f"å°ºå¯¸éæ¿¾: {obj_size:.1f}mm ä¸åœ¨ {MIN_MOSQUITO_SIZE_MM}-{MAX_MOSQUITO_SIZE_MM}mm ç¯„åœ")
                        else:
                            # ç„¡æ³•ä¼°è¨ˆæ·±åº¦æ™‚ä¿ç•™ï¼ˆé¿å…éåº¦éæ¿¾ï¼‰
                            valid_detections.append(detection)
                    else:
                        valid_detections.append(detection)

                # æ›´æ–°ç‚ºéæ¿¾å¾Œçš„æª¢æ¸¬çµæœ
                detections = valid_detections
            else:
                # å–®ç›®æ¨¡å¼æˆ–ç„¡æ·±åº¦ä¼°è¨ˆï¼šä½¿ç”¨åƒç´ ç´šéæ¿¾
                detections = self._apply_monocular_filters(detections)

        # è¿½è¹¤æ§åˆ¶ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.tracker and detections:
            self.tracker.update(detections)
            self.stats['tracking_active'] = True
        else:
            self.stats['tracking_active'] = False

        # å„²å­˜å…‰ç…§åº¦è³‡è¨Š
        self.stats['last_illumination_info'] = illumination_info

        # è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶è©³ç´°è³‡è¨Š
        if detections:
            self._log_detection_details(detections)

        # ç¹ªè£½ AI æ¨™è¨»ï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰
        result_left = self._draw_detections_with_depth(result_left, detections)

        # æ·»åŠ ç³»çµ±è³‡è¨Š
        self._draw_system_info(result_left, detections, illumination_info)

        # æ ¹æ“šä¸²æµæ¨¡å¼çµ„åˆç•«é¢
        if self.stream_mode == "side_by_side" and right_frame is not None:
            # ä¸¦æ’é¡¯ç¤º
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            combined = np.hstack([result_left, right_frame])
            # æ·»åŠ åˆ†éš”ç·š
            mid = combined.shape[1] // 2
            cv2.line(combined, (mid, 0), (mid, combined.shape[0]),
                    (0, 255, 255), 2)
            return combined

        elif self.stream_mode == "dual_stream" and right_frame is not None:
            # é›™ä¸²æµæ¨¡å¼
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            return result_left, right_frame

        else:
            # å–®ä¸€è¦–è§’
            return result_left

    def _draw_detections_with_depth(self, frame: np.ndarray, detections: list) -> np.ndarray:
        """
        ç¹ªè£½æª¢æ¸¬çµæœï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰

        Args:
            frame: å½±åƒå¹€
            detections: æª¢æ¸¬çµæœåˆ—è¡¨

        Returns:
            æ¨™è¨»å¾Œçš„å½±åƒ
        """
        # å…ˆç¹ªè£½åŸºæœ¬æª¢æ¸¬æ¡†
        frame = self.detector.draw_detections(frame, detections)

        # å¦‚æœå•Ÿç”¨æ·±åº¦ä¼°è¨ˆï¼Œæ·»åŠ æ·±åº¦è³‡è¨Š
        if self.depth_estimator and detections:
            for detection in detections:
                bbox = detection.get('bbox')
                depth = detection.get('depth')
                distance_cm = detection.get('distance_cm')

                if bbox and distance_cm:
                    x1, y1, x2, y2 = bbox
                    obj_size = detection.get('object_size_mm', 0)

                    # åœ¨æª¢æ¸¬æ¡†ä¸‹æ–¹é¡¯ç¤ºè·é›¢èˆ‡å°ºå¯¸è³‡è¨Š
                    if obj_size > 0:
                        distance_text = f"{distance_cm:.1f}cm | {obj_size:.1f}mm"
                    else:
                        distance_text = f"{distance_cm:.1f}cm"
                    text_size = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    text_x = x1
                    text_y = y2 + 25

                    # ç¹ªè£½èƒŒæ™¯
                    cv2.rectangle(frame,
                                (text_x, text_y - text_size[1] - 5),
                                (text_x + text_size[0] + 5, text_y + 5),
                                (0, 0, 0), -1)

                    # ç¹ªè£½è·é›¢èˆ‡å°ºå¯¸æ–‡å­—ï¼ˆæ©™è‰²ï¼‰
                    cv2.putText(frame, distance_text,
                              (text_x + 2, text_y),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)

        return frame

    def _update_unique_targets(self, detections: list):
        """æ›´æ–°å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰"""
        current_time = time.time()

        # æ¨™è¨˜æ‰€æœ‰è¿½è¹¤ç‚ºã€Œå¯èƒ½æ¶ˆå¤±ã€
        for track_id in self.active_tracks:
            self.active_tracks[track_id]['lost_frames'] += 1

        # ç‚ºæ¯å€‹æª¢æ¸¬åˆ†é…æˆ–åŒ¹é…è¿½è¹¤ID
        for detection in detections:
            center = detection.get('center', (0, 0))
            matched_track_id = None
            min_distance = self.track_distance_threshold

            # å°‹æ‰¾æœ€è¿‘çš„ç¾æœ‰è¿½è¹¤
            for track_id, track_info in self.active_tracks.items():
                if track_info['lost_frames'] > self.track_lost_frames_max:
                    continue  # å·²æ¶ˆå¤±çš„è¿½è¹¤ä¸åŒ¹é…

                track_center = track_info['center']
                distance = np.sqrt((center[0] - track_center[0])**2 +
                                 (center[1] - track_center[1])**2)

                if distance < min_distance:
                    min_distance = distance
                    matched_track_id = track_id

            # æ›´æ–°æˆ–å‰µå»ºè¿½è¹¤
            if matched_track_id is not None:
                # åŒ¹é…åˆ°ç¾æœ‰è¿½è¹¤
                self.active_tracks[matched_track_id]['center'] = center
                self.active_tracks[matched_track_id]['last_seen'] = current_time
                self.active_tracks[matched_track_id]['lost_frames'] = 0
                detection['track_id'] = matched_track_id
            else:
                # æ–°ç›®æ¨™
                new_track_id = self.next_track_id
                self.next_track_id += 1
                self.active_tracks[new_track_id] = {
                    'center': center,
                    'last_seen': current_time,
                    'lost_frames': 0
                }
                self.stats['unique_targets'] += 1
                detection['track_id'] = new_track_id

        # æ¸…ç†é•·æ™‚é–“æœªè¦‹çš„è¿½è¹¤
        tracks_to_remove = [
            track_id for track_id, track_info in self.active_tracks.items()
            if track_info['lost_frames'] > self.track_lost_frames_max
        ]
        for track_id in tracks_to_remove:
            del self.active_tracks[track_id]
            # æ¸…ç†å–®ç›®éæ¿¾å™¨æ­·å²æ•¸æ“š
            if track_id in self.detection_history:
                del self.detection_history[track_id]

    def _apply_monocular_filters(self, detections: list) -> list:
        """
        å–®ç›®æ¨¡å¼éæ¿¾å™¨ï¼ˆç„¡æ·±åº¦è³‡è¨Šæ™‚ä½¿ç”¨ï¼‰
        åŒ…å«ï¼šæª¢æ¸¬æ¡†å¤§å°ã€å¯¬é«˜æ¯”ã€æ™‚é–“é€£çºŒæ€§ã€é‹å‹•åˆç†æ€§
        """
        from config import (ENABLE_BBOX_SIZE_FILTER, MIN_BBOX_SIZE_PX, MAX_BBOX_SIZE_PX,
                           ENABLE_ASPECT_RATIO_FILTER, MIN_ASPECT_RATIO, MAX_ASPECT_RATIO,
                           ENABLE_TEMPORAL_FILTER, MIN_CONSECUTIVE_FRAMES,
                           ENABLE_MOTION_FILTER, MAX_MOVEMENT_PX_PER_FRAME,
                           MAX_STATIC_FRAMES, STATIC_THRESHOLD_PX)
        from collections import deque

        valid_detections = []

        for detection in detections:
            bbox = detection.get('bbox')
            if not bbox:
                continue

            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            center = detection.get('center', ((x1+x2)//2, (y1+y2)//2))
            track_id = detection.get('track_id')

            # 1. æª¢æ¸¬æ¡†å¤§å°éæ¿¾
            if ENABLE_BBOX_SIZE_FILTER:
                size = max(width, height)
                if size < MIN_BBOX_SIZE_PX or size > MAX_BBOX_SIZE_PX:
                    logger.debug(f"æ¡†å¤§å°éæ¿¾: {size}px ä¸åœ¨ {MIN_BBOX_SIZE_PX}-{MAX_BBOX_SIZE_PX}px ç¯„åœ")
                    continue

            # 2. å¯¬é«˜æ¯”éæ¿¾
            if ENABLE_ASPECT_RATIO_FILTER:
                aspect_ratio = width / max(height, 1)
                if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
                    logger.debug(f"å¯¬é«˜æ¯”éæ¿¾: {aspect_ratio:.2f} ä¸åœ¨ {MIN_ASPECT_RATIO}-{MAX_ASPECT_RATIO} ç¯„åœ")
                    continue

            # 3. æ™‚é–“é€£çºŒæ€§éæ¿¾
            if ENABLE_TEMPORAL_FILTER and track_id is not None:
                if track_id not in self.detection_history:
                    self.detection_history[track_id] = {
                        'frames': 1,
                        'positions': deque(maxlen=10),
                        'static_frames': 0
                    }
                    self.detection_history[track_id]['positions'].append(center)
                else:
                    self.detection_history[track_id]['frames'] += 1
                    self.detection_history[track_id]['positions'].append(center)

                # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å°‘å¹€æ•¸
                if self.detection_history[track_id]['frames'] < MIN_CONSECUTIVE_FRAMES:
                    logger.debug(f"æ™‚é–“é€£çºŒæ€§éæ¿¾: track_{track_id} åƒ…å‡ºç¾ {self.detection_history[track_id]['frames']} å¹€")
                    continue

            # 4. é‹å‹•åˆç†æ€§éæ¿¾
            if ENABLE_MOTION_FILTER and track_id is not None and track_id in self.detection_history:
                history = self.detection_history[track_id]
                positions = history['positions']

                if len(positions) >= 2:
                    prev_pos = positions[-2]
                    curr_pos = center
                    movement = np.sqrt((curr_pos[0] - prev_pos[0])**2 + (curr_pos[1] - prev_pos[1])**2)

                    # ç§»å‹•éå¿«éæ¿¾
                    if movement > MAX_MOVEMENT_PX_PER_FRAME:
                        logger.debug(f"é‹å‹•éå¿«éæ¿¾: track_{track_id} ç§»å‹• {movement:.1f}px > {MAX_MOVEMENT_PX_PER_FRAME}px")
                        continue

                    # éœæ­¢éä¹…éæ¿¾
                    if movement < STATIC_THRESHOLD_PX:
                        history['static_frames'] += 1
                        if history['static_frames'] > MAX_STATIC_FRAMES:
                            logger.debug(f"éœæ­¢éä¹…éæ¿¾: track_{track_id} éœæ­¢ {history['static_frames']} å¹€")
                            continue
                    else:
                        history['static_frames'] = 0

            # é€šéæ‰€æœ‰éæ¿¾å™¨
            valid_detections.append(detection)

        return valid_detections

    def _log_detection_details(self, detections: list):
        """è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶çš„è©³ç´°è³‡è¨Š"""
        from config import (MIN_MOSQUITO_SIZE_MM, MAX_MOSQUITO_SIZE_MM,
                           MIN_BBOX_SIZE_PX, MAX_BBOX_SIZE_PX,
                           MIN_ASPECT_RATIO, MAX_ASPECT_RATIO)

        for detection in detections:
            track_id = detection.get('track_id', 'N/A')
            confidence = detection.get('confidence', 0)
            bbox = detection.get('bbox')

            if not bbox:
                continue

            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            bbox_size = max(width, height)
            aspect_ratio = width / max(height, 1)

            # ç‰©ç†å°ºå¯¸èˆ‡è·é›¢è³‡è¨Š
            distance_cm = detection.get('distance_cm', 0)
            obj_size_mm = detection.get('object_size_mm', 0)

            # é‹å‹•è³‡è¨Š
            speed_info = ""
            if track_id != 'N/A' and track_id in self.detection_history:
                history = self.detection_history[track_id]
                positions = history['positions']
                if len(positions) >= 2:
                    prev_pos = positions[-2]
                    curr_pos = positions[-1]
                    movement = np.sqrt((curr_pos[0] - prev_pos[0])**2 + (curr_pos[1] - prev_pos[1])**2)
                    speed_info = f"| é€Ÿåº¦: {movement:.1f}px/å¹€"

                static_frames = history.get('static_frames', 0)
                if static_frames > 0:
                    speed_info += f" (éœæ­¢{static_frames}å¹€)"

            # éæ¿¾å™¨è³‡è¨Š
            filter_info = []
            filter_info.append(f"æ¡†: {bbox_size}px/{MIN_BBOX_SIZE_PX}-{MAX_BBOX_SIZE_PX}px")
            filter_info.append(f"å¯¬é«˜æ¯”: {aspect_ratio:.2f}/{MIN_ASPECT_RATIO}-{MAX_ASPECT_RATIO}")

            if distance_cm > 0 and obj_size_mm > 0:
                filter_info.append(f"è·é›¢: {distance_cm:.1f}cm")
                filter_info.append(f"å°ºå¯¸: {obj_size_mm:.1f}mm/{MIN_MOSQUITO_SIZE_MM}-{MAX_MOSQUITO_SIZE_MM}mm")

            # è¼¸å‡ºè©³ç´°æ—¥èªŒ
            logger.info(f"[æª¢æ¸¬] ID:{track_id} | ä¿¡å¿ƒ: {confidence:.3f} | {' | '.join(filter_info)} {speed_info}")

    def _draw_system_info(self, frame: np.ndarray, detections: list, illumination_info: dict):
        """åœ¨ç•«é¢ä¸Šç¹ªè£½ç³»çµ±è³‡è¨Š"""
        y_pos = 30
        line_height = 35

        # å”¯ä¸€ç›®æ¨™æ•¸
        cv2.putText(frame, f"Unique Targets: {self.stats['unique_targets']}", (10, y_pos),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        y_pos += line_height

        # è¿½è¹¤ç‹€æ…‹
        if not self.has_pt:
            tracking_text = "NONE"
            tracking_color = (128, 128, 128)
        elif self.stats['tracking_active']:
            tracking_text = "TRACKING"
            tracking_color = (0, 255, 0)
        else:
            tracking_text = "STANDBY"
            tracking_color = (128, 128, 128)

        cv2.putText(frame, f"Status: {tracking_text}", (10, y_pos),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, tracking_color, 2)
        y_pos += line_height

        # FPS
        elapsed = time.time() - self.stats['start_time']
        fps = self.stats['total_frames'] / elapsed if elapsed > 0 else 0
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, y_pos),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

        # ç³»çµ±è³‡è¨Šï¼ˆå³ä¸‹è§’ï¼‰
        line_height = 20
        info_y = frame.shape[0] - 80

        # æ™‚é–“ï¼ˆå³ä¸‹è§’æœ€ä¸‹æ–¹ï¼‰
        current_time = time.strftime("%H:%M:%S")
        time_font_size = 0.35
        time_thickness = 1
        time_size = cv2.getTextSize(current_time, cv2.FONT_HERSHEY_SIMPLEX, time_font_size, time_thickness)[0]
        time_x = frame.shape[1] - time_size[0] - 10
        time_y = frame.shape[0] - 10
        cv2.putText(frame, current_time, (time_x, time_y),
                   cv2.FONT_HERSHEY_SIMPLEX, time_font_size, (200, 200, 200), time_thickness)

        # å…‰ç…§åº¦ï¼ˆå³ä¸‹è§’å‘ä¸Šï¼‰
        # Debug: è¼¸å‡ºå…‰ç…§åº¦ç‹€æ…‹
        if illumination_info['illumination'] < 50:  # åªåœ¨å…‰ç·šè¼ƒæš—æ™‚è¼¸å‡º
            logger.debug(f"Illumination: {illumination_info['illumination']}, Status: {illumination_info['status']}")

        illumination_color = (0, 255, 0)  # ç¶ è‰²ï¼šæ­£å¸¸
        if illumination_info['status'] == 'paused':
            illumination_color = (0, 0, 255)  # ç´…è‰²ï¼šæš«åœ
        elif illumination_info['status'] == 'warning':
            illumination_color = (0, 165, 255)  # æ©™è‰²ï¼šè­¦å‘Š
        elif illumination_info['status'] == 'resumed':
            illumination_color = (0, 255, 255)  # é»ƒè‰²ï¼šå·²æ¢å¾©

        illumination_text = f"Lux: {illumination_info['illumination']}"
        illumination_size = cv2.getTextSize(illumination_text, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)[0]
        illumination_x = frame.shape[1] - illumination_size[0] - 10
        illumination_y = frame.shape[0] - 30
        cv2.putText(frame, illumination_text, (illumination_x, illumination_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, illumination_color, 1)

    def run(self):
        """é‹è¡Œä¸»å¾ªç’°"""
        # è¨­ç½®ä¿¡è™Ÿè™•ç†å™¨ï¼Œç¢ºä¿ Ctrl+C èƒ½ç«‹å³è¢«æ•æ‰
        def signal_handler(signum, frame):
            logger.info("\n\nğŸ›‘ ç”¨æˆ¶ä¸­æ–· (Ctrl+C)")
            self._running = False
            # å¼·åˆ¶é€€å‡ºï¼ˆå¦‚æœæ­£åœ¨åŸ·è¡Œé˜»å¡æ“ä½œï¼‰
            sys.exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        # é–‹å•Ÿæ”åƒé ­
        cap = cv2.VideoCapture(self.camera_id)

        # è¨­ç½®æ”åƒé ­è§£æåº¦ï¼ˆä½¿ç”¨æª¢æ¸¬åˆ°çš„æœ€ä½³é…ç½®ï¼‰
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
        cap.set(cv2.CAP_PROP_FPS, self.camera_fps)

        if not cap.isOpened():
            logger.error("âœ— ç„¡æ³•é–‹å•Ÿæ”åƒé ­")
            return

        logger.info(f"âœ“ æ”åƒé ­å·²é–‹å•Ÿ (ID: {self.camera_id})")
        logger.info(f"âœ“ è§£æåº¦: {self.camera_width}Ã—{self.camera_height}@{self.camera_fps}fps")

        try:
            while self._running:  # ä½¿ç”¨åŸ·è¡Œæ¨™èªŒæ§åˆ¶è¿´åœˆ
                ret, frame = cap.read()
                if not ret:
                    logger.error("âœ— ç„¡æ³•è®€å–å½±åƒ")
                    break

                # âš¡ è™•ç†å½±åƒï¼ˆæ¯å¹€åªåŸ·è¡Œä¸€æ¬¡ AI æª¢æ¸¬ï¼‰
                result = self.process_frame(frame)

                # æ›´æ–°ä¸²æµ
                if self.stream_mode == "dual_stream" and isinstance(result, tuple):
                    # é›™ä¸²æµæ¨¡å¼
                    self.server.update_frame(result[0])
                    if self.server_right:
                        self.server_right.update_frame(result[1])
                    # ä¸éœ€è¦æœ¬åœ°é¡¯ç¤ºï¼ˆheadless modeï¼‰
                else:
                    # å–®ä¸€ä¸²æµ
                    self.server.update_frame(result)

                # å®šæœŸè¼¸å‡ºç‹€æ…‹ï¼ˆæ¯ 500 å¹€ï¼‰
                if self.stats['total_frames'] % 500 == 0:
                    elapsed = time.time() - self.stats['start_time']
                    fps = self.stats['total_frames'] / elapsed if elapsed > 0 else 0

                    # ç²å–å…‰ç…§åº¦è³‡è¨Š
                    illum_info = self.stats.get('last_illumination_info', {})
                    lux = illum_info.get('illumination', 0)
                    lux_status = illum_info.get('status', 'unknown')
                    ai_paused = illum_info.get('paused', False)

                    # ç²å–å¼±ä¿¡å¿ƒå­˜æª”æ•¸
                    saved_samples = getattr(self.detector, 'saved_sample_count', 0)

                    logger.info(f"[ç‹€æ…‹] FPS: {fps:.1f} | "
                          f"å”¯ä¸€ç›®æ¨™: {self.stats['unique_targets']} | "
                          f"å­˜æª”: {saved_samples} | "
                          f"è¿½è¹¤: {'å•Ÿç”¨' if self.stats['tracking_active'] else 'åœç”¨'} | "
                          f"è¾¨è­˜: {'åœç”¨' if ai_paused else 'å•Ÿç”¨'} | "
                          f"Lux: {lux} ({lux_status})")

                # ç°¡å–®å»¶æ™‚æ§åˆ¶å¹€ç‡
                time.sleep(FRAME_DELAY)  # å¹€å»¶æ™‚

        except Exception as e:
            logger.error(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

            traceback.print_exc()
            self._running = False

        finally:
            # æ¸…ç†è³‡æºï¼ˆç¢ºä¿åŸ·è¡Œï¼‰
            logger.info("\nâ³ æ­£åœ¨é—œé–‰ç³»çµ±...")
            self._cleanup(cap)

    def _cleanup(self, cap):
        """æ¸…ç†æ‰€æœ‰è³‡æºï¼ˆå„ªé›…é—œé–‰ï¼‰"""
        logger.info("   â†’ é‡‹æ”¾æ”åƒé ­...")
        try:
            cap.release()
        except:
            pass

        logger.info("   â†’ é—œé–‰ä¸²æµä¼ºæœå™¨...")
        try:
            if self.server:
                self.server.shutdown()
        except:
            pass

        try:
            if self.server_right:
                self.server_right.shutdown()
        except:
            pass

        logger.info("   â†’ é—œé–‰é›²å°...")
        try:
            if self.pt_controller:
                self.pt_controller.close()
        except:
            pass

        logger.info("   â†’ é—œé–‰è¿½è¹¤å™¨...")
        try:
            if self.tracker:
                if hasattr(self.tracker, 'stop'):
                    self.tracker.stop()
        except:
            pass

        logger.info("   â†’ é—œé–‰æª¢æ¸¬å™¨...")
        try:
            if self.detector:
                if hasattr(self.detector, 'cleanup'):
                    self.detector.cleanup()
        except:
            pass

        # é¡¯ç¤ºçµ±è¨ˆ
        logger.info("=" * 60)
        logger.info("ğŸ“Š ç³»çµ±çµ±è¨ˆ")
        logger.info("=" * 60)
        logger.info(f"ç¸½å¹€æ•¸: {self.stats['total_frames']}")
        logger.info(f"å”¯ä¸€ç›®æ¨™: {self.stats['unique_targets']}")
        if hasattr(self.detector, 'saved_sample_count'):
            logger.info(f"å·²å„²å­˜æ¨£æœ¬: {self.detector.saved_sample_count}")
        elapsed = time.time() - self.stats['start_time']
        if elapsed > 0:
            logger.info(f"é‹è¡Œæ™‚é–“: {elapsed:.1f} ç§’")
            logger.info(f"å¹³å‡ FPS: {self.stats['total_frames'] / elapsed:.1f}")
        logger.info("=" * 60)
        logger.info("âœ… ç³»çµ±å·²é—œé–‰")


def detect_best_camera_config(camera_id: int = 0) -> dict:
    """
    è‡ªå‹•æª¢æ¸¬æ”åƒé ­ä¸¦é¸æ“‡æœ€ä½³é…ç½®

    å˜—è©¦å¸¸è¦‹è§£æåº¦ï¼ˆå¾é«˜åˆ°ä½ï¼‰ï¼Œé¸æ“‡ç›¸æ©Ÿæ”¯æ´çš„æœ€é«˜è§£æåº¦ï¼š
    - 3840Ã—1080 @ 60fps (é›™ç›® Full HD)
    - 1920Ã—1080 @ 60fps (å–®ç›® Full HD)
    - 1280Ã—720 @ 60fps (HD)
    - 640Ã—480 @ 30fps (VGA, fallback)

    Args:
        camera_id: æ”åƒé ­ ID

    Returns:
        dict: {
            'width': int,
            'height': int,
            'fps': int,
            'is_dual': bool,
            'resolution_name': str
        }
    """
    # å¸¸è¦‹è§£æåº¦é…ç½®ï¼ˆå¾é«˜åˆ°ä½å„ªå…ˆç´šï¼‰
    resolutions = [
        {'width': 3840, 'height': 1080, 'fps': 60, 'name': 'é›™ç›® Full HD (3840Ã—1080@60fps)', 'is_dual': True},
        {'width': 1920, 'height': 1080, 'fps': 60, 'name': 'å–®ç›® Full HD (1920Ã—1080@60fps)', 'is_dual': False},
        {'width': 1280, 'height': 720, 'fps': 60, 'name': 'HD (1280Ã—720@60fps)', 'is_dual': False},
        {'width': 1280, 'height': 720, 'fps': 30, 'name': 'HD (1280Ã—720@30fps)', 'is_dual': False},
        {'width': 640, 'height': 480, 'fps': 30, 'name': 'VGA (640Ã—480@30fps)', 'is_dual': False},
    ]

    logger.info(f"ğŸ” æ­£åœ¨æª¢æ¸¬æ”åƒé ­ {camera_id} çš„æœ€ä½³é…ç½®...")

    best_config = None

    for config in resolutions:
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            continue

        # å˜—è©¦è¨­ç½®è§£æåº¦
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, config['width'])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config['height'])
        cap.set(cv2.CAP_PROP_FPS, config['fps'])

        # è®€å–ä¸€å¹€é©—è­‰
        ret, frame = cap.read()
        cap.release()

        if ret and frame is not None:
            actual_width = frame.shape[1]
            actual_height = frame.shape[0]

            # æª¢æŸ¥æ˜¯å¦æˆåŠŸè¨­ç½®ç‚ºç›®æ¨™è§£æåº¦ï¼ˆå®¹è¨±å°å¹…åå·®ï¼‰
            width_match = abs(actual_width - config['width']) <= 10
            height_match = abs(actual_height - config['height']) <= 10

            if width_match and height_match:
                best_config = {
                    'width': actual_width,
                    'height': actual_height,
                    'fps': config['fps'],
                    'is_dual': config['is_dual'],
                    'resolution_name': config['name']
                }
                logger.info(f"âœ… æ‰¾åˆ°æ”¯æ´çš„è§£æåº¦: {config['name']}")
                logger.info(f"   å¯¦éš›è§£æåº¦: {actual_width}Ã—{actual_height}")
                break
            else:
                logger.debug(f"âš ï¸  {config['name']} ä¸æ”¯æ´ (å¯¦éš›: {actual_width}Ã—{actual_height})")

    # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ”¯æ´çš„è§£æåº¦ï¼Œä½¿ç”¨é è¨­å€¼
    if best_config is None:
        logger.warning(f"âš ï¸  ç„¡æ³•æª¢æ¸¬åˆ°æ”¯æ´çš„è§£æåº¦ï¼Œä½¿ç”¨é è¨­é…ç½®")
        best_config = {
            'width': 640,
            'height': 480,
            'fps': 30,
            'is_dual': False,
            'resolution_name': 'VGA (640Ã—480@30fps) - é è¨­'
        }

    return best_config


def detect_dual_camera(camera_id: int = 0) -> bool:
    """
    è‡ªå‹•æª¢æ¸¬æ˜¯å¦ç‚ºé›™ç›®æ”åƒé ­ï¼ˆèˆŠç‰ˆç›¸å®¹å‡½æ•¸ï¼‰

    å»ºè­°ä½¿ç”¨ detect_best_camera_config() ä¾†ç²å–å®Œæ•´é…ç½®

    Args:
        camera_id: æ”åƒé ­ ID

    Returns:
        True: é›™ç›®æ”åƒé ­ï¼ˆå¯¬åº¦ >= 2560ï¼‰
        False: å–®ç›®æ”åƒé ­
    """
    config = detect_best_camera_config(camera_id)
    return config['is_dual']


def main():
    """ä¸»ç¨‹å¼å…¥å£ï¼ˆåƒæ•¸å‹ï¼‰"""
    parser = argparse.ArgumentParser(
        description='ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # è‡ªå‹•æª¢æ¸¬æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰
  python streaming_tracking_system.py

  # æŒ‡å®šå–®ç›®æ¨¡å¼
  python streaming_tracking_system.py --single

  # æŒ‡å®šé›™ç›®æ¨¡å¼
  python streaming_tracking_system.py --dual

  # è‡ªå®šç¾©ä¸²å£å’Œä¸²æµæ¨¡å¼
  python streaming_tracking_system.py --port COM3 --mode side_by_side

  # è‡ªå®šç¾© RTSP æ¨æµåœ°å€
  python streaming_tracking_system.py --rtsp-url rtsp://192.168.1.100:8554/mosquito

  # åœç”¨ RTSP æ¨æµ
  python streaming_tracking_system.py --no-rtsp
        """
    )

    # ä¸²å£åƒæ•¸
    default_port = 'COM3' if sys.platform.startswith('win') else '/dev/ttyUSB0'
    parser.add_argument('--port', '-p', type=str, default=default_port,
                       help=f'Arduino ä¸²å£ (é è¨­: {default_port})')

    # æ”åƒé ­åƒæ•¸
    parser.add_argument('--camera', '-c', type=int, default=0,
                       help='æ”åƒé ­ ID (é è¨­: 0)')

    camera_group = parser.add_mutually_exclusive_group()
    camera_group.add_argument('--dual', action='store_true',
                             help='å¼·åˆ¶ä½¿ç”¨é›™ç›®æ¨¡å¼')
    camera_group.add_argument('--single', action='store_true',
                             help='å¼·åˆ¶ä½¿ç”¨å–®ç›®æ¨¡å¼')

    # ä¸²æµåƒæ•¸
    parser.add_argument('--mode', '-m', type=str,
                       choices=['single', 'side_by_side', 'dual_stream'],
                       default='single',
                       help='ä¸²æµæ¨¡å¼ (é è¨­: single)')

    parser.add_argument('--port-http', type=int, default=5000,
                       help='HTTP ä¸²æµç«¯å£ (é è¨­: 5000)')

    # æ¨¡å‹åƒæ•¸
    parser.add_argument('--model', type=str, default='models/mosquito',
                       help='AI æ¨¡å‹è·¯å¾‘ (é è¨­: models/mosquito)')

    # æ¨£æœ¬å„²å­˜åƒæ•¸
    parser.add_argument('--no-save-samples', action='store_true',
                       help='åœç”¨ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬å„²å­˜')

    # RTSP æ¨æµåƒæ•¸ï¼ˆé è¨­åœç”¨ï¼‰
    parser.add_argument('--rtsp', action='store_true',
                       help='å•Ÿç”¨ RTSP æ¨æµï¼ˆé è¨­åœç”¨ï¼‰')
    parser.add_argument('--rtsp-url', type=str, default='rtsp://0.0.0.0:8554/mosquito',
                       help='RTSP æ¨æµåœ°å€ (é è¨­: rtsp://0.0.0.0:8554/mosquito)')
    parser.add_argument('--rtsp-bitrate', type=int, default=2000,
                       help='RTSP è¦–é »ç¢¼ç‡ kbps (é è¨­: 2000ï¼Œç¯„åœ: 1000-3000)')

    args = parser.parse_args()

    logger.info("=" * 60)
    logger.info("ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµ")
    logger.info("=" * 60)

    # è‡ªå‹•æª¢æ¸¬æˆ–ä½¿ç”¨æŒ‡å®šçš„æ”åƒé ­æ¨¡å¼
    camera_config = None
    if args.dual:
        dual_camera = True
        camera_width = CAMERA_DUAL_WIDTH
        camera_height = CAMERA_DUAL_HEIGHT
        camera_fps = CAMERA_DUAL_FPS
        logger.info("ğŸ“· æ”åƒé ­æ¨¡å¼: é›™ç›®ï¼ˆæ‰‹å‹•æŒ‡å®šï¼‰")
        logger.info(f"   ä½¿ç”¨é…ç½®: {camera_width}Ã—{camera_height}@{camera_fps}fps")
    elif args.single:
        dual_camera = False
        camera_width = 1920
        camera_height = 1080
        camera_fps = 60
        logger.info("ğŸ“· æ”åƒé ­æ¨¡å¼: å–®ç›®ï¼ˆæ‰‹å‹•æŒ‡å®šï¼‰")
        logger.info(f"   ä½¿ç”¨é…ç½®: {camera_width}Ã—{camera_height}@{camera_fps}fps")
    else:
        logger.info("ğŸ“· è‡ªå‹•æª¢æ¸¬æ”åƒé ­æœ€ä½³é…ç½®...")
        camera_config = detect_best_camera_config(args.camera)
        dual_camera = camera_config['is_dual']
        camera_width = camera_config['width']
        camera_height = camera_config['height']
        camera_fps = camera_config['fps']
        logger.info(f"   æœ€ä½³é…ç½®: {camera_config['resolution_name']}")

    # é¡¯ç¤ºé…ç½®
    logger.info("âš™ï¸  ç³»çµ±é…ç½®:")
    logger.info(f"   - Arduino ä¸²å£: {args.port}")
    logger.info(f"   - æ”åƒé ­ ID: {args.camera}")
    logger.info(f"   - æ”åƒé ­æ¨¡å¼: {'é›™ç›®' if dual_camera else 'å–®ç›®'}")
    logger.info(f"   - æ”åƒé ­è§£æåº¦: {camera_width}Ã—{camera_height}@{camera_fps}fps")
    logger.info(f"   - ä¸²æµæ¨¡å¼: {args.mode}")
    logger.info(f"   - HTTP ç«¯å£: {args.port_http}")
    logger.info(f"   - æ¨£æœ¬å„²å­˜: {'åœç”¨' if args.no_save_samples else 'å•Ÿç”¨'}")
    logger.info(f"   - RTSP æ¨æµ: {'âœ“ å•Ÿç”¨' if args.rtsp else 'âœ— åœç”¨ (é è¨­)'}")
    if args.rtsp:
        logger.info(f"     â†’ æ¨æµåœ°å€: {args.rtsp_url}")
        logger.info(f"     â†’ ç¢¼ç‡: {args.rtsp_bitrate} kbps")
    else:
        logger.info(f"     â„¹ï¸  æç¤º: ä½¿ç”¨é è¨­ HTTP-MJPEG ä¸²æµï¼ˆè‹¥éœ€ RTSP è«‹åŠ ä¸Š --rtsp åƒæ•¸ï¼‰")

    # å‰µå»ºä¸¦é‹è¡Œç³»çµ±
    system = StreamingTrackingSystem(
        arduino_port=args.port,
        camera_id=args.camera,
        model_path=args.model,
        http_port=args.port_http,
        dual_camera=dual_camera,
        stream_mode=args.mode,
        save_samples=not args.no_save_samples,
        enable_rtsp=args.rtsp,
        rtsp_url=args.rtsp_url if args.rtsp else None,
        rtsp_bitrate=args.rtsp_bitrate
    )

    # å°‡æª¢æ¸¬åˆ°çš„è§£æåº¦é…ç½®æ‡‰ç”¨åˆ°ç³»çµ±
    system.camera_width = camera_width
    system.camera_height = camera_height
    system.camera_fps = camera_fps

    system.run()


if __name__ == "__main__":
    main()
