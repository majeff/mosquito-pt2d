# Copyright 2025 Arduino PT2D Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from streaming_server import StreamingServer
from mosquito_detector import MosquitoDetector
from mosquito_tracker import MosquitoTracker
from pt2d_controller import PT2DController
from depth_estimator import DepthEstimator
from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
from collections import deque
import sys
import cv2
import numpy as np
import time
import argparse
import signal
import logging
import traceback
from pathlib import Path

# é…ç½® logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class StreamingTrackingSystem:
    """æ•´åˆçš„èšŠå­è¿½è¹¤èˆ‡ä¸²æµç³»çµ±"""

    def __init__(self,
                 arduino_port: str = '/dev/ttyUSB0',
                 camera_id: int = 0,
                 model_path: str = "models/mosquito",
                 http_port: int = 5000,
                 dual_camera: bool = True,
                 stream_mode: str = "single",
                 save_samples: bool = None,
                 sample_conf_range: tuple = None,
                 enable_depth: bool = True,
                 enable_rtsp: bool = False,
                 rtsp_url: str = None,
                 rtsp_bitrate: int = 2000):
        """
        åˆå§‹åŒ–å®Œæ•´ç³»çµ±

        Args:
            arduino_port: Arduino ä¸²å£
            camera_id: æ”åƒé ­ ID
            model_path: AI æ¨¡å‹è·¯å¾‘
            http_port: HTTP ä¸²æµç«¯å£
            dual_camera: æ˜¯å¦ç‚ºé›™ç›®æ”åƒé ­
            stream_mode: ä¸²æµæ¨¡å¼ ("side_by_side", "single", "dual_stream")
            save_samples: æ˜¯å¦å„²å­˜ä¸­ç­‰ä¿¡å¿ƒåº¦æ¨£æœ¬
            sample_conf_range: æ¨£æœ¬ä¿¡å¿ƒåº¦ç¯„åœ (min, max)
            enable_depth: æ˜¯å¦å•Ÿç”¨æ·±åº¦ä¼°è¨ˆ
            enable_rtsp: æ˜¯å¦å•Ÿç”¨ RTSP æ¨æµ
            rtsp_url: RTSP æ¨æµåœ°å€
            rtsp_bitrate: RTSP è¦–é »ç¢¼ç‡ (kbps)
        """
        logger.info("=" * 60)
        logger.info("ğŸ¦Ÿ èšŠå­è¿½è¹¤ç³»çµ± + æ‰‹æ©Ÿä¸²æµæ•´åˆå•Ÿå‹•")
        logger.info("=" * 60)

        # ç³»çµ±é…ç½®
        self.dual_camera = dual_camera
        self.stream_mode = stream_mode
        self.camera_id = camera_id
        self.enable_depth = enable_depth and dual_camera  # æ·±åº¦ä¼°è¨ˆéœ€è¦é›™ç›®æ”åƒé ­
        self._running = True  # é‹è¡Œæ¨™èªŒï¼Œç”¨æ–¼å„ªé›…é€€å‡º

        # æ”åƒé ­è§£æåº¦é…ç½®ï¼ˆå¾ config_loader è®€å–ï¼‰
        self.camera_width = config.camera_dual_width if dual_camera else 1920
        self.camera_height = config.camera_dual_height if dual_camera else 1080
        self.camera_fps = config.camera_dual_fps if dual_camera else 60

        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total_frames': 0,
            'unique_targets': 0,          # å”¯ä¸€ç›®æ¨™æ•¸ï¼ˆå»é‡å¾Œï¼‰
            'tracking_active': False,
            'samples_saved': 0,
            'start_time': time.time(),
            'last_illumination_info': {}
        }

        # å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰
        self.active_tracks = {}           # {track_id: {'last_seen': time, 'center': (x,y), 'lost_frames': int}}
        self.next_track_id = 1
        self.track_distance_threshold = 100  # åƒç´ è·é›¢é–¾å€¼ï¼ˆ<100èªç‚ºæ˜¯åŒä¸€ç›®æ¨™ï¼‰
        self.track_lost_frames_max = 30     # è¶…é30å¹€æœªè¦‹è¦–ç‚ºæ¶ˆå¤±

        # å–®ç›®éæ¿¾å™¨è¿½è¹¤æ•¸æ“šï¼ˆç”¨æ–¼æ™‚é–“é€£çºŒæ€§å’Œé‹å‹•åˆç†æ€§æª¢æŸ¥ï¼‰
        self.detection_history = {}       # {track_id: {'frames': int, 'positions': deque, 'static_frames': int}}

        # 1. åˆå§‹åŒ– AI æª¢æ¸¬å™¨ï¼ˆåªå‰µå»ºä¸€æ¬¡ï¼ï¼‰
        logger.info("[1/5] åˆå§‹åŒ– AI æª¢æ¸¬å™¨...")

        # å¦‚æœæœªæŒ‡å®šåƒæ•¸ï¼Œå‰‡ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        if save_samples is None:
            save_samples = config.save_uncertain_samples
        if sample_conf_range is None:
            sample_conf_range = config.uncertain_conf_range

        self.detector = MosquitoDetector(
            model_path=model_path,
            confidence_threshold=config.confidence_threshold,  # ä½¿ç”¨æ–°é…ç½®
            imgsz=config.imgsz,  # ä½¿ç”¨æ–°é…ç½®
            save_uncertain_samples=save_samples,
            uncertain_conf_range=sample_conf_range,  # ä½¿ç”¨å‚³å…¥çš„åƒæ•¸
            save_dir="uncertain_samples",
            max_samples=config.max_samples,  # ä½¿ç”¨æ–°é…ç½®
            save_interval=config.save_interval,  # ä½¿ç”¨æ–°é…ç½®
            save_annotations=True,
            save_full_frame=False
        )
        logger.info(f"      âœ“ ä½¿ç”¨ {self.detector.backend.upper()} å¾Œç«¯")
        if save_samples:
            logger.info(f"      âœ“ æ¨£æœ¬å„²å­˜å·²å•Ÿç”¨ (ä¿¡å¿ƒåº¦ {sample_conf_range[0]}-{sample_conf_range[1]})")

        # 2. åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨
        logger.info("[2/5] åˆå§‹åŒ–é›²å°æ§åˆ¶å™¨...")
        try:
            self.pt_controller = PT2DController(config.arduino_port)
            # åˆå§‹åŒ–è¿½è¹¤å™¨æ™‚ä½¿ç”¨é…ç½®çš„åƒæ•¸
            logger.info("[3/5] åˆå§‹åŒ–è¿½è¹¤å™¨...")
            if self.has_pt:
                self.tracker = MosquitoTracker(
                    arduino_port=config.arduino_port,
                    camera_left_id=config.left_camera_id,
                    camera_right_id=config.right_camera_id,
                    camera_width=self.camera_width,
                    camera_height=self.camera_height
                )
                logger.info(f"      âœ“ è¿½è¹¤å™¨å·²å°±ç·’")
            else:
                self.tracker = None
                logger.warning(f"      âš  è¿½è¹¤å™¨æœªå•Ÿç”¨ï¼ˆéœ€è¦é›²å°é€£æ¥ï¼‰")
            if self.pt_controller.is_connected:
                logger.info(f"      âœ“ Arduino å·²é€£æ¥ ({config.arduino_port})")  # ä½¿ç”¨æ–°é…ç½®
                self.has_pt = True
                self.has_laser = True  # é›²å°é€£æ¥æˆåŠŸæ™‚å•Ÿç”¨é›·å°„åŠŸèƒ½
            else:
                logger.warning(f"      âš  ç„¡æ³•é€£æ¥ Arduinoï¼Œåƒ…é‹è¡Œæª¢æ¸¬æ¨¡å¼")
                self.has_pt = False
                self.has_laser = False
        except Exception as e:
            logger.warning(f"      âš  é›²å°åˆå§‹åŒ–å¤±æ•—: {e}")
            self.has_pt = False
            self.has_laser = False
            self.pt_controller = None

        # 3. åˆå§‹åŒ–è¿½è¹¤å™¨
        logger.info("[3/5] åˆå§‹åŒ–è¿½è¹¤å™¨...")
        if self.has_pt:
            self.tracker = MosquitoTracker(
                arduino_port=config.arduino_port,
                camera_device_id=config.left_camera_id,  # ä½¿ç”¨é…ç½®ä¸­çš„left_camera_idä½œä¸ºè®¾å¤‡ID
                camera_width=self.camera_width,  # ä½¿ç”¨é…ç½®
                camera_height=self.camera_height  # ä½¿ç”¨é…ç½®
            )
            logger.info(f"      âœ“ è¿½è¹¤å™¨å·²å°±ç·’")
        else:
            self.tracker = None
            logger.warning(f"      âš  è¿½è¹¤å™¨æœªå•Ÿç”¨ï¼ˆéœ€è¦é›²å°é€£æ¥ï¼‰")

        # 4. åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        logger.info("[4/6] åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨...")
        if self.enable_depth:
            # æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨ run() ä¸­æ ¹æ“šå¯¦éš›è§£æåº¦åˆå§‹åŒ–
            self.depth_estimator = None
            logger.info(f"      â³ æ·±åº¦ä¼°è¨ˆå™¨å°‡åœ¨é¦–å¹€æ™‚åˆå§‹åŒ–ï¼ˆæ ¹æ“šå¯¦éš›è§£æåº¦ï¼‰")
        else:
            self.depth_estimator = None
            logger.info(f"      âš  æ·±åº¦ä¼°è¨ˆæœªå•Ÿç”¨ï¼ˆéœ€è¦é›™ç›®æ”åƒé ­ï¼‰")

        # 5. åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨
        logger.info("[5/6] åˆå§‹åŒ–ä¸²æµä¼ºæœå™¨...")
        self.server = StreamingServer(
            http_port=config.stream_port,  # ä½¿ç”¨æ–°é…ç½®
            fps=config.stream_fps,  # ä½¿ç”¨æ–°é…ç½®
            rtsp_url=config.rtsp_url if enable_rtsp else None  # ä½¿ç”¨æ–°é…ç½®
        )
        self.server.run(threaded=True)
        logger.info(f"      âœ“ ä¸²æµä¼ºæœå™¨å·²å•Ÿå‹• (ç«¯å£ {http_port})")

        # 6. åˆå§‹åŒ– RTSP æ¨æµï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        self.enable_rtsp = enable_rtsp
        self.rtsp_url = rtsp_url
        self.rtsp_bitrate = rtsp_bitrate
        if enable_rtsp and rtsp_url:
            logger.info("[6/6] åˆå§‹åŒ– RTSP æ¨æµ...")
            logger.info(f"      âœ“ RTSP å·²é…ç½®")
            logger.info(f"         URL: {rtsp_url}")
            logger.info(f"         ç¢¼ç‡: {rtsp_bitrate}kbps")
            logger.info(f"      â³ RTSP æ¨æµå°‡åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹•...")
            # ç¨å¾Œåœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
            self.rtsp_enabled = False
            self.rtsp_initialized = False
        else:
            if enable_rtsp:
                logger.warning(f"âš ï¸  RTSP å·²å•Ÿç”¨ä½† URL æœªè¨­å®š")
            self.rtsp_enabled = False
            self.rtsp_initialized = True

        # é›™ä¸²æµæ¨¡å¼ï¼ˆåƒ…åœ¨ dual_stream æ¨¡å¼ï¼‰
        self.server_right = None
        if stream_mode == "dual_stream" and dual_camera:
            self.server_right = StreamingServer(http_port=http_port + 1, fps=30)
            self.server_right.run(threaded=True)
            logger.info(f"      âœ“ å³å´ä¸²æµå·²å•Ÿå‹• (ç«¯å£ {http_port + 1})")

        logger.info("=" * 60)
        logger.info("ğŸ‰ ç³»çµ±å·²å®Œå…¨å•Ÿå‹•ï¼")
        logger.info("=" * 60)
        # ç”Ÿæˆè¨ªå•åœ°å€
        device_ip = config.device_ip
        device_url = f"http://{device_ip}:{config.stream_port}"
        logger.info(f"ğŸ“± è¨­å‚™è¨ªå•: {device_url}")
        if config.external_url:
            logger.info(f"ğŸŒ é ç«¯è¨ªå•: {config.external_url}")

        if self.server_right:
            right_device_url = f"http://{device_ip}:{config.stream_port + 1}"
            logger.info(f"ğŸ“± å³å´è¦–è§’ï¼ˆè¨­å‚™ï¼‰: {right_device_url}")
            if config.external_url:
                logger.info(f"ğŸŒ å³å´è¦–è§’ï¼ˆé ç«¯ï¼‰: {config.external_url}")

        logger.info("â„¹ï¸  ç³»çµ±é…ç½®:")
        logger.info(f"   - AI æª¢æ¸¬: âœ“ å•Ÿç”¨ ({self.detector.backend.upper()})")
        logger.info(f"   - é›²å°è¿½è¹¤: {'âœ“ å•Ÿç”¨' if self.has_pt else 'âœ— åœç”¨'}")
        logger.info(f"   - é›·å°„æ¨™è¨˜: {'âœ“ å•Ÿç”¨' if self.has_laser else 'âœ— åœç”¨'}")
        logger.info(f"   - æ·±åº¦ä¼°è¨ˆ: {'âœ“ å•Ÿç”¨' if self.enable_depth else 'âœ— åœç”¨'}")
        logger.info(f"   - æ¨£æœ¬å„²å­˜: {'âœ“ å•Ÿç”¨' if save_samples else 'âœ— åœç”¨'}")
        logger.info(f"   - é›™ç›®æ”åƒé ­: {'âœ“ å•Ÿç”¨' if dual_camera else 'âœ— åœç”¨'}")
        logger.info(f"   - ä¸²æµæ¨¡å¼: {stream_mode}")

        logger.info("âš¡ æ€§èƒ½èªªæ˜:")
        logger.info(f"   - AI è² è¼‰: æ¯å¹€åªåŸ·è¡Œä¸€æ¬¡æª¢æ¸¬")
        logger.info(f"   - è¨˜æ†¶é«”: å–®ä¸€æª¢æ¸¬å™¨å¯¦ä¾‹")
        logger.info(f"   - CPU: æœ€å„ªåŒ–åˆ©ç”¨")

        logger.info("ğŸ® æ§åˆ¶æ–¹å¼:")
        logger.info("   Ctrl+C - é€€å‡ºç³»çµ±")
        logger.info("   (é€šéç€è¦½å™¨è¨ªå• HTTP ä¸²æµæŸ¥çœ‹å½±åƒ)")

    def run(self):
        """ä¸»é‹è¡Œå¾ªç’°"""
        try:
            # æ‰“é–‹æ”åƒé ­
            cap = cv2.VideoCapture(self.camera_id)
            if not cap.isOpened():
                logger.error(f"âŒ ç„¡æ³•æ‰“é–‹æ”åƒé ­ {self.camera_id}")
                return

            # è¨­ç½®æ”åƒé ­åƒæ•¸
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
            cap.set(cv2.CAP_PROP_FPS, self.camera_fps)

            logger.info(f"ğŸ¥ æ”åƒé ­å·²é–‹å•Ÿ (è§£æåº¦: {self.camera_width}x{self.camera_height}, FPS: {self.camera_fps})")

            frame_count = 0
            start_time = time.time()

            while self._running:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("âš ï¸  ç„¡æ³•è®€å–å¹€")
                    break

                frame_count += 1

                # è™•ç†å¹€
                result = self.process_frame(frame)

                # ç™¼é€åˆ°ä¸²æµä¼ºæœå™¨
                if isinstance(result, tuple):
                    # é›™ä¸²æµæ¨¡å¼
                    self.server.update_frame(result[0])
                    if self.server_right:
                        self.server_right.update_frame(result[1])
                else:
                    self.server.update_frame(result)

                # å®šæœŸè¼¸å‡ºçµ±è¨ˆä¿¡æ¯
                if frame_count % 30 == 0:
                    elapsed = time.time() - start_time
                    fps = frame_count / elapsed
                    logger.debug(f"ğŸ“Š FPS: {fps:.1f}, å¹€æ•¸: {frame_count}, ç¨ç«‹ç›®æ¨™: {self.stats['unique_targets']}")

        except Exception as e:
            logger.error(f"âŒ é‹è¡Œå¾ªç’°éŒ¯èª¤: {e}")
            traceback.print_exc()
        finally:
            self._running = False
            if 'cap' in locals():
                cap.release()
            logger.info("ğŸ›‘ ç³»çµ±å·²åœæ­¢")

    def _draw_system_info(self, frame: np.ndarray, detections: list, illumination_info: dict) -> np.ndarray:
        """ç¹ªè£½æ™‚é–“åˆ°å¹€ä¸Š"""
        # ç¹ªè£½ç•¶å‰æ™‚é–“
        current_time = time.strftime("%Y-%m-%d %H:%M:%S")
        cv2.putText(frame, current_time, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame

    def get_system_stats(self) -> dict:
        """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯ï¼ˆä¾› HTML å‘ˆç¾ï¼‰"""
        elapsed_time = time.time() - self.stats['start_time']
        fps = self.stats['total_frames'] / elapsed_time if elapsed_time > 0 else 0
        
        return {
            'total_frames': self.stats['total_frames'],
            'unique_targets': self.stats['unique_targets'],
            'tracking_active': self.stats['tracking_active'],
            'samples_saved': self.stats['samples_saved'],
            'elapsed_time': elapsed_time,
            'fps': fps,
            'illumination_info': self.stats.get('last_illumination_info', {}),
            'active_tracks': len(self.active_tracks),
            'system_time': time.strftime("%Y-%m-%d %H:%M:%S")
        }

    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        è™•ç†å–®å¹€å½±åƒï¼ˆAI æª¢æ¸¬ + è¿½è¹¤ + æ¨™è¨»ï¼‰

        âš ï¸ é‡è¦ï¼šæ­¤å‡½æ•¸æ¯å¹€åªèª¿ç”¨ä¸€æ¬¡ AI æª¢æ¸¬ï¼Œä¸æœƒé‡è¤‡ï¼
        """
        self.stats['total_frames'] += 1

        # åœ¨ç¬¬ä¸€å¹€æ™‚å•Ÿå‹• RTSPï¼ˆéœ€è¦çŸ¥é“å¹€å°ºå¯¸ï¼‰
        if self.enable_rtsp and not self.rtsp_initialized:
            h, w = frame.shape[:2]
            logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RTSP...")
            logger.info(f"   RTSP URL: {self.rtsp_url}")
            logger.info(f"   RTSP ç¢¼ç‡: {self.rtsp_bitrate}kbps")
            logger.info(f"   å¹€å°ºå¯¸: {w}x{h}")
            try:
                if self.server.enable_rtsp_push(w, h, bitrate=self.rtsp_bitrate):
                    logger.info("âœ… RTSP æ¨æµå·²å•Ÿå‹•")
                    self.rtsp_enabled = True
                else:
                    logger.warning("âš ï¸  RTSP æ¨æµå•Ÿå‹•è¿”å› False")
            except Exception as e:
                logger.error(f"âŒ RTSP åˆå§‹åŒ–å¤±æ•—: {e}")
                traceback.print_exc()
            finally:
                self.rtsp_initialized = True

        # åˆ†é›¢å·¦å³ç•«é¢ï¼ˆå¦‚æœæ˜¯é›™ç›®ï¼‰
        if self.dual_camera:
            height, width = frame.shape[:2]
            mid = width // 2
            left_frame = frame[:, :mid]
            right_frame = frame[:, mid:]

            # é¦–æ¬¡é‹è¡Œæ™‚åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆä½¿ç”¨å¯¦éš›è§£æåº¦ï¼‰
            if self.enable_depth and self.depth_estimator is None:
                single_width = left_frame.shape[1]
                logger.info(f"ğŸ”§ åˆå§‹åŒ–æ·±åº¦ä¼°è¨ˆå™¨ï¼ˆå–®çœ¼è§£æåº¦: {single_width}Ã—{left_frame.shape[0]}ï¼‰")
                self.depth_estimator = DepthEstimator(
                    focal_length=3.0,        # é¡é ­ç„¦è· 3.0mm
                    baseline=120.0,          # é›™ç›®åŸºç·š 12cm
                    image_width=single_width,  # ä½¿ç”¨å¯¦éš›å–®çœ¼è§£æåº¦
                    sensor_width=5.0         # æ„Ÿå…‰å…ƒä»¶å¯¬åº¦
                )
                logger.info(f"      âœ“ æ·±åº¦ä¼°è¨ˆå·²å•Ÿç”¨ï¼ˆæ¸¬è·ç¯„åœ: 0.5-5mï¼‰")
        else:
            left_frame = frame
            right_frame = None

        # âš¡ AI æª¢æ¸¬ï¼ˆæ¯å¹€åªåŸ·è¡Œä¸€æ¬¡ï¼ï¼‰
        # é›™ç›®æ¨¡å¼ï¼šå‘ŠçŸ¥æª¢æ¸¬å™¨é€™æ˜¯å·¦çœ¼ç•«é¢ï¼Œåªéæ¿¾ä¸Šä¸‹é‚Šç·£
        detections, result_left, illumination_info = self.detector.detect(left_frame, is_dual_left=self.dual_camera)

        # éæ¿¾ç•°å¸¸ä¿¡å¿ƒåº¦å€¼ï¼ˆæ’é™¤ confidence == 1.0 çš„ç•°å¸¸æª¢æ¸¬ï¼‰
        if detections:
            detections = [d for d in detections if d.get('confidence', 0) < 1.0]
            if len([d for d in detections if d.get('confidence', 0) >= 1.0]) > 0:
                logger.debug(f"å·²éæ¿¾ {len([d for d in detections if d.get('confidence', 0) >= 1.0])} å€‹ä¿¡å¿ƒåº¦=1.0çš„ç•°å¸¸æª¢æ¸¬")

        # è¿½è¹¤å”¯ä¸€ç›®æ¨™
        if detections:
            self._update_unique_targets(detections)

            # ğŸ¯ æ·±åº¦ä¼°è¨ˆèˆ‡å°ºå¯¸éæ¿¾ï¼ˆå¦‚æœå•Ÿç”¨ä¸”æœ‰å³çœ¼å½±åƒï¼‰
            if self.depth_estimator and right_frame is not None:
                valid_detections = []
                for detection in detections:
                    bbox = detection.get('bbox')
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        # ä¼°è¨ˆæ·±åº¦èˆ‡å¯¦éš›å°ºå¯¸
                        depth_info = self.depth_estimator.estimate_depth_for_detection(
                            left_frame, right_frame, (x1, y1, x2, y2)
                        )
                        if depth_info:
                            detection['depth'] = depth_info['depth']
                            detection['distance_cm'] = depth_info['distance_cm']
                            detection['object_size_mm'] = depth_info.get('object_size_mm', 0)

                            # å°ºå¯¸éæ¿¾ï¼šåªä¿ç•™åˆç†å°ºå¯¸çš„æª¢æ¸¬
                            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
                            obj_size = depth_info.get('object_size_mm', 0)
                            if config.min_mosquito_size_mm <= obj_size <= config.max_mosquito_size_mm:
                                valid_detections.append(detection)

                        else:
                            # ç„¡æ³•ä¼°è¨ˆæ·±åº¦æ™‚ä¿ç•™ï¼ˆé¿å…éåº¦éæ¿¾ï¼‰
                            valid_detections.append(detection)
                    else:
                        valid_detections.append(detection)

                # æ›´æ–°ç‚ºéæ¿¾å¾Œçš„æª¢æ¸¬çµæœ
                detections = valid_detections
            else:
                # å–®ç›®æ¨¡å¼æˆ–ç„¡æ·±åº¦ä¼°è¨ˆï¼šä½¿ç”¨åƒç´ ç´šéæ¿¾
                detections = self._apply_monocular_filters(detections)

        # è¿½è¹¤æ§åˆ¶ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.tracker and detections:
            self.tracker.update(detections)
            self.stats['tracking_active'] = True
        else:
            self.stats['tracking_active'] = False

        # å„²å­˜å…‰ç…§åº¦è³‡è¨Š
        self.stats['last_illumination_info'] = illumination_info

        # è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶è©³ç´°è³‡è¨Š
        if detections:
            self._log_detection_details(detections)

        # ç¹ªè£½ AI æ¨™è¨»ï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰
        result_left = self._draw_detections_with_depth(result_left, detections)

        # æ·»åŠ ç³»çµ±è³‡è¨Š
        self._draw_system_info(result_left, detections, illumination_info)

        # æ ¹æ“šä¸²æµæ¨¡å¼çµ„åˆç•«é¢
        if self.stream_mode == "side_by_side" and right_frame is not None:
            # ä¸¦æ’é¡¯ç¤º
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            combined = np.hstack([result_left, right_frame])
            # æ·»åŠ åˆ†éš”ç·š
            mid = combined.shape[1] // 2
            cv2.line(combined, (mid, 0), (mid, combined.shape[0]),
                    (0, 255, 255), 2)
            return combined

        elif self.stream_mode == "dual_stream" and right_frame is not None:
            # é›™ä¸²æµæ¨¡å¼
            cv2.putText(right_frame, "Original (Right)", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            return result_left, right_frame

        else:
            # å–®ä¸€è¦–è§’
            return result_left

    def _draw_detections_with_depth(self, frame: np.ndarray, detections: list) -> np.ndarray:
        """
        ç¹ªè£½æª¢æ¸¬çµæœï¼ˆåŒ…å«æ·±åº¦è³‡è¨Šï¼‰

        Args:
            frame: å½±åƒå¹€
            detections: æª¢æ¸¬çµæœåˆ—è¡¨

        Returns:
            æ¨™è¨»å¾Œçš„å½±åƒ
        """
        # å…ˆç¹ªè£½åŸºæœ¬æª¢æ¸¬æ¡†
        frame = self.detector.draw_detections(frame, detections)

        # å¦‚æœå•Ÿç”¨æ·±åº¦ä¼°è¨ˆï¼Œæ·»åŠ æ·±åº¦è³‡è¨Š
        if self.depth_estimator and detections:
            for detection in detections:
                bbox = detection.get('bbox')
                depth = detection.get('depth')
                distance_cm = detection.get('distance_cm')

                if bbox and distance_cm:
                    x1, y1, x2, y2 = bbox
                    obj_size = detection.get('object_size_mm', 0)

                    # åœ¨æª¢æ¸¬æ¡†ä¸‹æ–¹é¡¯ç¤ºè·é›¢èˆ‡å°ºå¯¸è³‡è¨Š
                    if obj_size > 0:
                        distance_text = f"{distance_cm:.1f}cm | {obj_size:.1f}mm"
                    else:
                        distance_text = f"{distance_cm:.1f}cm"
                    text_size = cv2.getTextSize(distance_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    text_x = x1
                    text_y = y2 + 25

                    # ç¹ªè£½èƒŒæ™¯
                    cv2.rectangle(frame,
                                (text_x, text_y - text_size[1] - 5),
                                (text_x + text_size[0] + 5, text_y + 5),
                                (0, 0, 0), -1)

                    # ç¹ªè£½è·é›¢èˆ‡å°ºå¯¸æ–‡å­—ï¼ˆæ©™è‰²ï¼‰
                    cv2.putText(frame, distance_text,
                              (text_x + 2, text_y),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)

        return frame

    def _update_unique_targets(self, detections: list):
        """æ›´æ–°å”¯ä¸€ç›®æ¨™è¿½è¹¤ï¼ˆç°¡å–®å»é‡æ©Ÿåˆ¶ï¼‰"""
        current_time = time.time()

        # æ¨™è¨˜æ‰€æœ‰è¿½è¹¤ç‚ºã€Œå¯èƒ½æ¶ˆå¤±ã€
        for track_id in self.active_tracks:
            self.active_tracks[track_id]['lost_frames'] += 1

        # ç‚ºæ¯å€‹æª¢æ¸¬åˆ†é…æˆ–åŒ¹é…è¿½è¹¤ID
        for detection in detections:
            center = detection.get('center', (0, 0))
            matched_track_id = None
            min_distance = self.track_distance_threshold

            # å°‹æ‰¾æœ€è¿‘çš„ç¾æœ‰è¿½è¹¤
            for track_id, track_info in self.active_tracks.items():
                if track_info['lost_frames'] > self.track_lost_frames_max:
                    continue  # å·²æ¶ˆå¤±çš„è¿½è¹¤ä¸åŒ¹é…

                track_center = track_info['center']
                distance = np.sqrt((center[0] - track_center[0])**2 +
                                 (center[1] - track_center[1])**2)

                if distance < min_distance:
                    min_distance = distance
                    matched_track_id = track_id

            # æ›´æ–°æˆ–å‰µå»ºè¿½è¹¤
            if matched_track_id is not None:
                # åŒ¹é…åˆ°ç¾æœ‰è¿½è¹¤
                self.active_tracks[matched_track_id]['center'] = center
                self.active_tracks[matched_track_id]['last_seen'] = current_time
                self.active_tracks[matched_track_id]['lost_frames'] = 0
                detection['track_id'] = matched_track_id
            else:
                # æ–°ç›®æ¨™
                new_track_id = self.next_track_id
                self.next_track_id += 1
                self.active_tracks[new_track_id] = {
                    'center': center,
                    'last_seen': current_time,
                    'lost_frames': 0
                }
                self.stats['unique_targets'] += 1
                detection['track_id'] = new_track_id

        # æ¸…ç†é•·æ™‚é–“æœªè¦‹çš„è¿½è¹¤
        tracks_to_remove = [
            track_id for track_id, track_info in self.active_tracks.items()
            if track_info['lost_frames'] > self.track_lost_frames_max
        ]
        for track_id in tracks_to_remove:
            del self.active_tracks[track_id]
            # æ¸…ç†å–®ç›®éæ¿¾å™¨æ­·å²æ•¸æ“š
            if track_id in self.detection_history:
                del self.detection_history[track_id]

    def _apply_monocular_filters(self, detections: list) -> list:
        """
        å–®ç›®æ¨¡å¼éæ¿¾å™¨ï¼ˆç„¡æ·±åº¦è³‡è¨Šæ™‚ä½¿ç”¨ï¼‰
        åŒ…å«ï¼šæª¢æ¸¬æ¡†å¤§å°ã€å¯¬é«˜æ¯”ã€æ™‚é–“é€£çºŒæ€§ã€é‹å‹•åˆç†æ€§
        """
        # å¾é…ç½®åŠ è¼‰ç¯©é¸åƒæ•¸
        try:
            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
            ENABLE_BBOX_SIZE_FILTER = config.enable_bbox_size_filter
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            ENABLE_ASPECT_RATIO_FILTER = config.enable_aspect_ratio_filter
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
            ENABLE_TEMPORAL_FILTER = config.enable_temporal_filter
            MIN_CONSECUTIVE_FRAMES = config.min_consecutive_frames
            ENABLE_MOTION_FILTER = config.enable_motion_filter
            MAX_MOVEMENT_PX_PER_FRAME = config.max_movement_px_per_frame
            MAX_STATIC_FRAMES = config.max_static_frames
            STATIC_THRESHOLD_PX = config.static_threshold_px
        except ImportError:
            # é»˜èªå€¼
            ENABLE_BBOX_SIZE_FILTER = True
            MIN_BBOX_SIZE_PX = 10
            MAX_BBOX_SIZE_PX = 200
            ENABLE_ASPECT_RATIO_FILTER = True
            MIN_ASPECT_RATIO = 0.3
            MAX_ASPECT_RATIO = 3.0
            ENABLE_TEMPORAL_FILTER = True
            MIN_CONSECUTIVE_FRAMES = 3
            ENABLE_MOTION_FILTER = True
            MAX_MOVEMENT_PX_PER_FRAME = 150
            MAX_STATIC_FRAMES = 60
            STATIC_THRESHOLD_PX = 5

        valid_detections = []

        for detection in detections:
            bbox = detection.get('bbox')
            if not bbox:
                continue

            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            center = detection.get('center', ((x1+x2)//2, (y1+y2)//2))
            track_id = detection.get('track_id')

            # 1. æª¢æ¸¬æ¡†å¤§å°éæ¿¾
            if ENABLE_BBOX_SIZE_FILTER:
                size = max(width, height)
                if size < MIN_BBOX_SIZE_PX or size > MAX_BBOX_SIZE_PX:
                    logger.debug(f"æ¡†å¤§å°éæ¿¾: {size}px ä¸åœ¨ {MIN_BBOX_SIZE_PX}-{MAX_BBOX_SIZE_PX}px ç¯„åœ")
                    continue

            # 2. å¯¬é«˜æ¯”éæ¿¾
            if ENABLE_ASPECT_RATIO_FILTER:
                aspect_ratio = width / max(height, 1)
                if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
                    logger.debug(f"å¯¬é«˜æ¯”éæ¿¾: {aspect_ratio:.2f} ä¸åœ¨ {MIN_ASPECT_RATIO}-{MAX_ASPECT_RATIO} ç¯„åœ")
                    continue

            # 3. æ™‚é–“é€£çºŒæ€§éæ¿¾
            if ENABLE_TEMPORAL_FILTER and track_id is not None:
                if track_id not in self.detection_history:
                    self.detection_history[track_id] = {
                        'frames': 1,
                        'positions': deque(maxlen=10),
                        'static_frames': 0
                    }
                    self.detection_history[track_id]['positions'].append(center)
                else:
                    self.detection_history[track_id]['frames'] += 1
                    self.detection_history[track_id]['positions'].append(center)

                # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å°‘å¹€æ•¸
                if self.detection_history[track_id]['frames'] < MIN_CONSECUTIVE_FRAMES:
                    logger.debug(f"æ™‚é–“é€£çºŒæ€§éæ¿¾: track_{track_id} åƒ…å‡ºç¾ {self.detection_history[track_id]['frames']} å¹€")
                    continue

            # 4. é‹å‹•åˆç†æ€§éæ¿¾
            if ENABLE_MOTION_FILTER and track_id is not None and track_id in self.detection_history:
                history = self.detection_history[track_id]
                positions = history['positions']

                if len(positions) >= 2:
                    prev_pos = positions[-2]
                    curr_pos = center
                    movement = np.sqrt((curr_pos[0] - prev_pos[0])**2 + (curr_pos[1] - prev_pos[1])**2)

                    # ç§»å‹•éå¿«éæ¿¾
                    if movement > MAX_MOVEMENT_PX_PER_FRAME:
                        logger.debug(f"é‹å‹•éå¿«éæ¿¾: track_{track_id} ç§»å‹• {movement:.1f}px > {MAX_MOVEMENT_PX_PER_FRAME}px")
                        continue

                    # éœæ­¢éä¹…éæ¿¾
                    if movement < STATIC_THRESHOLD_PX:
                        history['static_frames'] += 1
                        if history['static_frames'] > MAX_STATIC_FRAMES:
                            logger.debug(f"éœæ­¢éä¹…éæ¿¾: track_{track_id} éœæ­¢ {history['static_frames']} å¹€")
                            continue
                    else:
                        history['static_frames'] = 0

            # é€šéæ‰€æœ‰éæ¿¾å™¨
            valid_detections.append(detection)

        return valid_detections

    def _log_detection_details(self, detections: list):
        """è¼¸å‡ºæª¢æ¸¬ç‰©ä»¶çš„è©³ç´°è³‡è¨Š"""
        # å¾é…ç½®åŠ è¼‰ç‰©ç†åƒæ•¸
        try:
            from config_loader import config  # ä½¿ç”¨æ–°çš„é…ç½®åŠ è¼‰æ¨¡çµ„
            MIN_MOSQUITO_SIZE_MM = config.min_mosquito_size_mm
            MAX_MOSQUITO_SIZE_MM = config.max_mosquito_size_mm
            MIN_BBOX_SIZE_PX = config.min_bbox_size_px
            MAX_BBOX_SIZE_PX = config.max_bbox_size_px
            MIN_ASPECT_RATIO = config.min_aspect_ratio
            MAX_ASPECT_RATIO = config.max_aspect_ratio
        except ImportError:
            # é»˜èªå€¼
            MIN_MOSQUITO_SIZE_MM = 3
            MAX_MOSQUITO_SIZE_MM = 15
            MIN_BBOX_SIZE_PX = 10
            MAX_BBOX_SIZE_PX = 200
            MIN_ASPECT_RATIO = 0.3
            MAX_ASPECT_RATIO = 3.0

        for detection in detections:
            bbox = detection.get('bbox', [0, 0, 0, 0])
            x1, y1, x2, y2 = bbox
            width = x2 - x1
            height = y2 - y1
            conf = detection.get('confidence', 0)
            track_id = detection.get('track_id')
            distance_cm = detection.get('distance_cm', None)
            obj_size_mm = detection.get('object_size_mm', None)

            logger.info(f"æª¢æ¸¬çµæœ: track_id={track_id}, ä¿¡å¿ƒåº¦={conf:.2f}, ä½ç½®=({x1},{y1}), å°ºå¯¸={width}x{height}"
                       + (f", è·é›¢={distance_cm:.1f}cm, å°ºå¯¸={obj_size_mm:.1f}mm" if distance_cm and obj_size_mm else ""))


def main():
    """èšŠå­è¿½è¹¤ç³»çµ±ä¸»ç¨‹åº"""
    parser = argparse.ArgumentParser(
        description="èšŠå­è¿½è¹¤ç³»çµ± - æ•´åˆ AI æª¢æ¸¬ã€ä¸²æµèˆ‡æ§åˆ¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python streaming_tracking_system.py
  python streaming_tracking_system.py --port /dev/ttyUSB0 --camera 0
  python streaming_tracking_system.py --single --no-save-samples
        """
    )

    # æ·»åŠ å‘½ä»¤è¡Œåƒæ•¸
    parser.add_argument('--port', '-p', type=str, default=config.arduino_port,
                       help='Arduino ä¸²å£ (é è¨­: %(default)s)')
    parser.add_argument('--camera', '-c', type=int, default=0,
                       help='æ”åƒé ­ ID (é è¨­: %(default)s)')
    parser.add_argument('--model', '-m', type=str, default="models/mosquito",
                       help='AI æ¨¡å‹è·¯å¾‘ (é è¨­: %(default)s)')
    parser.add_argument('--port-http', type=int, default=config.stream_port,
                       help='HTTP ä¸²æµç«¯å£ (é è¨­: %(default)s)')
    parser.add_argument('--mode', type=str, default="single",
                       choices=["single", "side_by_side", "dual_stream"],
                       help='ä¸²æµæ¨¡å¼ (é è¨­: %(default)s)')
    parser.add_argument('--single', action='store_true',
                       help='å–®ç›®æ¨¡å¼ (ç¦ç”¨é›™ç›®æ·±åº¦ä¼°è¨ˆ)')
    parser.add_argument('--dual', action='store_true',
                       help='å¼·åˆ¶å•Ÿç”¨é›™ç›®æ¨¡å¼')
    parser.add_argument('--no-save-samples', action='store_true',
                       help='ç¦ç”¨ä¸ç¢ºå®šæ¨£æœ¬å„²å­˜')
    parser.add_argument('--enable-rtsp', action='store_true',
                       help='å•Ÿç”¨ RTSP æ¨æµ')
    parser.add_argument('--rtsp-url', type=str, default=None,
                       help='RTSP æ¨æµåœ°å€')
    parser.add_argument('--rtsp-bitrate', type=int, default=2000,
                       help='RTSP ç¢¼ç‡ (kbps, é è¨­: %(default)s)')

    args = parser.parse_args()

    # æª¢æŸ¥åƒæ•¸è¡çª
    if args.single and args.dual:
        logger.error("âŒ éŒ¯èª¤: --single å’Œ --dual ä¸èƒ½åŒæ™‚ä½¿ç”¨")
        sys.exit(1)

    # åˆ¤æ–·æ”åƒé ­æ¨¡å¼
    if args.single:
        dual_camera = False
    elif args.dual:
        dual_camera = True
    else:
        dual_camera = None  # è‡ªå‹•åˆ¤æ–·

    try:
        # åˆå§‹åŒ–ä¸¦é‹è¡Œç³»çµ±
        system = StreamingTrackingSystem(
            arduino_port=args.port,
            camera_id=args.camera,
            model_path=args.model,
            http_port=args.port_http,
            dual_camera=dual_camera,
            stream_mode=args.mode,
            save_samples=not args.no_save_samples,
            enable_rtsp=args.enable_rtsp,
            rtsp_url=args.rtsp_url,
            rtsp_bitrate=args.rtsp_bitrate
        )

        # å•Ÿå‹•ç³»çµ±
        system.run()

    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ ç”¨æˆ¶å·²ä¸­æ­¢ç³»çµ±")
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±éŒ¯èª¤: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
